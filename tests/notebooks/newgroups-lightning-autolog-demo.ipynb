{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0060a3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ Logging you into Galileo\n",
      "\n",
      "üîê How would you like to login? \n",
      "Enter one of the following: email\n",
      "email\n",
      "üöÄ You're logged in to Galileo as ben@rungalileo.io!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 0. Log in to Galileo!\n",
    "\"\"\"\n",
    "\n",
    "import dataquality\n",
    "\n",
    "dataquality.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c93a1ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(api_url='http://localhost:8000', minio_url='127.0.0.1:9000', minio_access_key='minioadmin', minio_secret_key='minioadmin', auth_method=<AuthMethod.email: 'email'>, token='eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJiZW5AcnVuZ2FsaWxlby5pbyIsImV4cCI6MTYzMzcyMTIyMH0.oY37cpqnQ4igpCgtyWIKDYqkhWYhZ-AF3JK0IfedW_w', current_user='ben@rungalileo.io', current_project_id=UUID('42c82a33-eccf-4679-9535-457446ef6c40'), current_run_id=UUID('35b71cb3-6124-4578-8346-fa4f53b29cc5'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataquality.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50131e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ú® Initializing project wealthy_blue_hyena\n",
      "üèÉ‚Äç‚ôÇÔ∏è Starting run upset_beige_mole\n",
      "üõ∞ Created project, wealthy_blue_hyena, and new run, upset_beige_mole.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 0.1 Create your first project!\n",
    "\"\"\"\n",
    "\n",
    "dataquality.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84325664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(api_url='http://localhost:8000', minio_url='127.0.0.1:9000', minio_access_key='minioadmin', minio_secret_key='minioadmin', auth_method=<AuthMethod.email: 'email'>, token='eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJiZW5AcnVuZ2FsaWxlby5pbyIsImV4cCI6MTYzMzcyMTIyMH0.oY37cpqnQ4igpCgtyWIKDYqkhWYhZ-AF3JK0IfedW_w', current_user='ben@rungalileo.io', current_project_id='58c309a3-dcfd-474f-9762-1fc42971a017', current_run_id='f4083d8f-b673-4d85-a140-dbdab261b7fe')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataquality.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6854d67e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 0.2 Install some dependencies for this workflow exercise.\n",
    "\"\"\"\n",
    "\n",
    "%pip install -q torch sklearn transformers pandas numpy pytorch_lightning torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c1487f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 1.\n",
    "\n",
    "Log your datasets with Galileo.\n",
    "\n",
    "Create the Newsgroup dataset class. Using huggingface Bert Tokenizer.\n",
    "\n",
    "We are introducing some noise to these datasets because \n",
    "the newsgroup dataset is already well labeled.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from transformers import DistilBertTokenizerFast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Use the GalileoModelConfig and GalileoDataConfig to keep track of Galileo metrics for logging\n",
    "from dataquality.core.integrations.config import GalileoModelConfig, GalileoDataConfig\n",
    "\n",
    "\n",
    "def introduce_label_errors(df: pd.DataFrame, column: str, shuffle_percent: int) -> pd.DataFrame:\n",
    "    arr = df[column].values\n",
    "    shuffle = np.random.choice(\n",
    "        np.arange(arr.shape[0]), \n",
    "        round(arr.shape[0] * shuffle_percent / 100), \n",
    "        replace=False)\n",
    "    arr[np.sort(shuffle)] = arr[shuffle]\n",
    "    df[column] = arr\n",
    "    return df\n",
    "    \n",
    "\n",
    "class NewsgroupDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, split: str) -> None:\n",
    "        newsgroups = fetch_20newsgroups(subset=\"train\" if split == \"training\" else \"test\", \n",
    "                                        remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "        self.dataset = pd.DataFrame()\n",
    "        self.dataset[\"text\"] = newsgroups.data\n",
    "        self.dataset[\"label\"] = newsgroups.target\n",
    "        self.dataset = self.dataset[:23]\n",
    "        \n",
    "        # Shuffle some percentage of the training dataset \n",
    "        # to force create mislabeled samples\n",
    "        if split == \"training\":\n",
    "            self.dataset = introduce_label_errors(self.dataset, \"label\", 11)\n",
    "\n",
    "        #\n",
    "        # üî≠ Logging Inputs with Galileo!\n",
    "        #\n",
    "        self.gconfig = GalileoDataConfig(text=self.dataset['text'], labels=self.dataset['label'])\n",
    "\n",
    "#         for i in range(len(self.dataset)):\n",
    "#             dataquality.log_input_data({\n",
    "#                 \"id\": i,\n",
    "#                 \"text\": self.dataset[\"text\"][i],\n",
    "#                 \"gold\": str(self.dataset[\"label\"][i]),\n",
    "#                 \"split\": split})\n",
    "\n",
    "        tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "        self.encodings = tokenizer(self.dataset[\"text\"].tolist(), truncation=True, padding=True)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.encodings[\"input_ids\"][idx])\n",
    "        attention_mask = torch.tensor(self.encodings[\"attention_mask\"][idx])\n",
    "        y = self.dataset[\"label\"][idx]\n",
    "        return idx, x, attention_mask, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9ed9fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 2.\n",
    "\n",
    "Log model outputs with Galileo.\n",
    "\n",
    "We are using a DistilBERT pytorch lightning class for text classification.\n",
    "\"\"\"\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from transformers import DistilBertForSequenceClassification, AdamW, DistilBertConfig, AutoModel\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "class LightningDistilBERT(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=DistilBertConfig(num_labels=20))\n",
    "        self.feature_extractor = AutoModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.val_acc = torchmetrics.Accuracy()\n",
    "        self.test_acc = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, x, attention_mask, x_idxs, epoch, split):\n",
    "        out = self.model(x, attention_mask=attention_mask)\n",
    "        log_probs = F.log_softmax(out.logits, dim=1)\n",
    "        probs = F.softmax(out.logits, dim=1)\n",
    "        encoded_layers = self.feature_extractor(x, return_dict=False)[0]\n",
    "        \n",
    "        # Logging with Galileo!\n",
    "        self.g_model_config = GalileoModelConfig(emb=[i[0] for i in encoded_layers.tolist()], probs=probs.tolist(), ids=x_idxs.tolist())\n",
    "        \n",
    "#         if x_idxs is not None:\n",
    "#             for i in range(len(x_idxs)):\n",
    "#                 index = int(x_idxs[i])\n",
    "#                 prob = probs[i].detach().cpu().numpy().tolist()\n",
    "#                 emb = encoded_layers[i, 0].detach().cpu().numpy().tolist()\n",
    "#                 #\n",
    "#                 # üî≠ Logging outputs with Galileo!\n",
    "#                 #\n",
    "#                 dataquality.log_model_output({\n",
    "#                     \"id\": int(x_idxs[i]),\n",
    "#                     \"epoch\": epoch,\n",
    "#                     \"split\": split,\n",
    "#                     \"emb\": emb,\n",
    "#                     \"prob\": prob,\n",
    "#                     \"pred\": str(int(np.argmax(prob)))})\n",
    "        return log_probs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"Model training step.\"\"\"\n",
    "        x_idxs, x, attention_mask, y = batch\n",
    "        log_probs = self(x=x, attention_mask=attention_mask, x_idxs=x_idxs, epoch=self.current_epoch, split=\"training\")\n",
    "        loss = F.nll_loss(log_probs, y)\n",
    "        self.train_acc(torch.argmax(log_probs, 1), y)\n",
    "        self.log(\"train_acc\", self.train_acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"Model validation step.\"\"\"\n",
    "        x_idxs, x, attention_mask, y = batch\n",
    "        log_probs = self(x=x, attention_mask=attention_mask, x_idxs=x_idxs, epoch=self.current_epoch, split=\"validation\")\n",
    "        loss = F.nll_loss(log_probs, y)\n",
    "        self.val_acc(torch.argmax(log_probs, 1), y)\n",
    "        self.log(\"val_acc\", self.val_acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx): \n",
    "        \"\"\"Model test step.\"\"\"\n",
    "        x_idxs, x, attention_mask, y = batch\n",
    "        log_probs = self(x=x, attention_mask=attention_mask, x_idxs=x_idxs, epoch=self.current_epoch, split=\"test\")\n",
    "        loss = F.nll_loss(log_probs, y)\n",
    "        self.test_acc(torch.argmax(log_probs, 1), y)\n",
    "        self.log(\"test_acc\", self.test_acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Model optimizers.\"\"\"\n",
    "        return torch.optim.AdamW(filter(lambda p: p.requires_grad, self.parameters()), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bdd6325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name              | Type                                | Params\n",
      "--------------------------------------------------------------------------\n",
      "0 | model             | DistilBertForSequenceClassification | 67.0 M\n",
      "1 | feature_extractor | DistilBertModel                     | 66.4 M\n",
      "2 | train_acc         | Accuracy                            | 0     \n",
      "3 | val_acc           | Accuracy                            | 0     \n",
      "4 | test_acc          | Accuracy                            | 0     \n",
      "--------------------------------------------------------------------------\n",
      "133 M     Trainable params\n",
      "0         Non-trainable params\n",
      "133 M     Total params\n",
      "533.327   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benepstein/Documents/GitHub/dataquality/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/benepstein/Documents/GitHub/dataquality/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:322: UserWarning: The number of training samples (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "/Users/benepstein/Documents/GitHub/dataquality/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:372: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/Users/benepstein/Documents/GitHub/dataquality/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e796c05728344ca81407cd61ea9ea56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benepstein/.pyenv/versions/3.9.6/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/inspect.py:351: LightningDeprecationWarning: The `LightningModule.datamodule` property is deprecated in v1.3 and will be removed in v1.5. Access the datamodule through using `self.trainer.datamodule` instead.\n",
      "  value = getattr(object, key)\n",
      "/Users/benepstein/.pyenv/versions/3.9.6/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/inspect.py:351: LightningDeprecationWarning: The `LightningModule.loaded_optimizer_states_dict` property is deprecated in v1.4 and will be removed in v1.6.\n",
      "  value = getattr(object, key)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "‚òÅÔ∏è Uploading Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benepstein/Documents/GitHub/dataquality/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:372: UserWarning: Your test_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/Users/benepstein/Documents/GitHub/dataquality/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca22d14322fe43e09c504cb0a93c55d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.1304347813129425}\n",
      "--------------------------------------------------------------------------------\n",
      "done!\n",
      "‚òÅÔ∏è Uploading Data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.1304347813129425}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 3.\n",
    "\n",
    "Instantiate a model and train it with PyTorch Lightning.\n",
    "\"\"\"\n",
    "\n",
    "# Use the PyTorch Lightning Callback to log data to Galileo\n",
    "from dataquality.core.integrations.lightning import DataQualityCallback\n",
    "\n",
    "model = LightningDistilBERT()\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(NewsgroupDataset(\"training\"), batch_size=8, shuffle=True)\n",
    "validation_dataloader = torch.utils.data.DataLoader(NewsgroupDataset(\"validation\"), batch_size=8, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(NewsgroupDataset(\"test\"), batch_size=8, shuffle=True)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=2, num_sanity_val_steps=0, callbacks=[(DataQualityCallback())])\n",
    "\n",
    "trainer.fit(model, train_dataloader, validation_dataloader)\n",
    "trainer.test(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "762d150f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Cleaning up\n"
     ]
    }
   ],
   "source": [
    "dataquality.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126297c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
