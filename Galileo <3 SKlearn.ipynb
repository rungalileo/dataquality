{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8cddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dataquality sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import dataquality as dq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d71d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset  \n",
    "## Loading some samples from public csv imdb sentiment data (Link: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews )\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_train[\"id\"] = list(range(len(df_train)))\n",
    "\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_test[\"id\"] = list(range(len(df_test)))\n",
    "\n",
    "# Train data\n",
    "train_data = df_train['review']\n",
    "train_labels  = df_train['sentiment']\n",
    "\n",
    "# Test data\n",
    "test_data = df_test['review']\n",
    "test_labels  = df_test['sentiment']\n",
    "\n",
    "# Load pre-trained sentence transformer model\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "\n",
    "# Encode train and test data\n",
    "train_embeddings = model.encode(train_data, show_progress_bar=True)\n",
    "test_embeddings = model.encode(test_data, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45c8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "dq.set_console_url(\"my_console_url\")\n",
    "dq.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc383cc9",
   "metadata": {},
   "source": [
    "# When integrating with Galileo, you have 3 options\n",
    "\n",
    "## Option 1 (Simple and fast)\n",
    "In option 1, you can simply train your classifier, log the final probabilities, and upload. This is quick and easy, and will provide many valuable insights (as long as your model was well trained).\n",
    "\n",
    "We fit the model, log the probabilities of the model, and log the embeddings from sentence_transformers to Galileo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7705f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MLP classifier on encoded data\n",
    "NUM_ITERS = 100\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=NUM_ITERS)\n",
    "classifier.fit(train_embeddings, train_labels)\n",
    "\n",
    "dq.init(\"text_classification\", project_name=\"sklearn-example\", run_name=\"option_1\")\n",
    "\n",
    "# Change these depending on your dataframe columns\n",
    "text_col = \"review\"\n",
    "label_col = \"sentiment\"\n",
    "dq.log_dataset(\n",
    "    df_train, split=\"training\", text=text_col, label=label_col\n",
    ")\n",
    "dq.log_dataset(\n",
    "    df_test, split=\"test\", text=text_col, label=label_col\n",
    ")\n",
    "\n",
    "train_probs = classifier.predict_proba(train_embeddings)\n",
    "test_probs = classifier.predict_proba(test_embeddings)\n",
    "\n",
    "dq.log_model_outputs(\n",
    "    embs=train_embeddings, \n",
    "    probs=train_probs, \n",
    "    ids=df_train[\"id\"].tolist(),\n",
    "    split=\"train\",\n",
    "    epoch=0\n",
    ")\n",
    "dq.log_model_outputs(\n",
    "    embs=test_embeddings, \n",
    "    probs=test_probs, \n",
    "    ids=df_test[\"id\"].tolist(),\n",
    "    split=\"test\",\n",
    "    epoch=0\n",
    ")\n",
    "\n",
    "dq.set_labels_for_run(sorted(df_train[label_col].unique()))\n",
    "dq.finish(create_data_embs=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718f455b",
   "metadata": {},
   "source": [
    "## Option 2 (Better embeddings)\n",
    "\n",
    "In this option, we extract out the final hidden layer before the classification and use those embeddings.\n",
    "\n",
    "Because you are freezing the BERT embeddings layer, these won't be as tuned to your data as the embeddings from HuggingFace for example (which fine-tunes BERTs layers), but these will adapt slightly to your data. So the embeddings in the UI will be slightly more tuned to your inputs.\n",
    "\n",
    "We add a simple function to extract those layers, and everything else it the same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3e0e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network._base import ACTIVATIONS\n",
    "\n",
    "def get_deepest_embeddings(classifier: MLPClassifier, inp: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Returns the deepest embeddings for an MLP classifier\"\"\"\n",
    "    data = inp.copy()\n",
    "    # Pass through the hidden layers\n",
    "    num_hidden_layers = len(classifier.hidden_layer_sizes)\n",
    "    for layer in range(num_hidden_layers):\n",
    "        data = np.matmul(data, classifier.coefs_[layer]) + classifier.intercepts_[layer]\n",
    "        # We don't want to run the activation over the final layer of embeddings for logging\n",
    "        if layer != num_hidden_layers-1:\n",
    "            ACTIVATIONS[classifier.activation](data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356cfbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MLP classifier on encoded data\n",
    "NUM_ITERS = 100\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=NUM_ITERS)\n",
    "classifier.fit(train_embeddings, train_labels)\n",
    "\n",
    "dq.init(\"text_classification\", project_name=\"sklearn-example\", run_name=\"option_2\")\n",
    "\n",
    "# Change these depending on your dataframe columns\n",
    "text_col = \"review\"\n",
    "label_col = \"sentiment\"\n",
    "dq.log_dataset(\n",
    "    df_train, split=\"training\", text=text_col, label=label_col\n",
    ")\n",
    "dq.log_dataset(\n",
    "    df_test, split=\"test\", text=text_col, label=label_col\n",
    ")\n",
    "\n",
    "train_probs = classifier.predict_proba(train_embeddings)\n",
    "test_probs = classifier.predict_proba(test_embeddings)\n",
    "\n",
    "# Here we extract the model's embeddings and log those instead\n",
    "model_train_embs = get_deepest_embeddings(classifier, train_embeddings)\n",
    "model_test_embs = get_deepest_embeddings(classifier, test_embeddings)\n",
    "\n",
    "dq.log_model_outputs(\n",
    "    embs=model_train_embs, \n",
    "    probs=train_probs, \n",
    "    ids=df_train[\"id\"].tolist(),\n",
    "    split=\"train\",\n",
    "    epoch=0\n",
    ")\n",
    "dq.log_model_outputs(\n",
    "    embs=model_test_embs, \n",
    "    probs=test_probs, \n",
    "    ids=df_test[\"id\"].tolist(),\n",
    "    split=\"test\",\n",
    "    epoch=0\n",
    ")\n",
    "\n",
    "dq.set_labels_for_run(sorted(df_train[label_col].unique()))\n",
    "dq.finish(create_data_embs=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a7f2a",
   "metadata": {},
   "source": [
    "## Option 3 (Better probability analysis)\n",
    "\n",
    "In this final option, we don't simply train the classifier for `NUM_ITERS`. Instead, we train it manually in a for-loop, and log the probabilities at every set interval. This will allow Galileo to build a deeper analysis of your model's understanding, and provide better insights into Data Error Potential (DEP) and other algorithms.\n",
    "\n",
    "This is the most complex, but can potentially provide the \"last mile\" results to find hidden data issues.\n",
    "\n",
    "Much of the code remains similar. Comments are available to explain the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf029fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "NUM_ITERS = 100\n",
    "# How frequently we log to Galileo. You can tune this and NUM_ITERS together for maximum control\n",
    "LOG_ITER_SIZE = 25\n",
    "# We set max_iter to 1, as we will be manually looping and partially training\n",
    "# We also set warm_start to True so we can continue to learn\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1, warm_start=True)\n",
    "classifier.fit(train_embeddings, train_labels)\n",
    "\n",
    "dq.init(\"text_classification\", project_name=\"sklearn-example\", run_name=\"option_3\")\n",
    "\n",
    "# Input data logging remains the same\n",
    "text_col = \"review\"\n",
    "label_col = \"sentiment\"\n",
    "dq.log_dataset(\n",
    "    df_train, split=\"training\", text=text_col, label=label_col\n",
    ")\n",
    "dq.log_dataset(\n",
    "    df_test, split=\"test\", text=text_col, label=label_col\n",
    ")\n",
    "\n",
    "epoch = 0\n",
    "for it in tqdm(range(NUM_ITERS)):\n",
    "    classifier.partial_fit(train_embeddings, train_labels)\n",
    "    # Log every LOG_ITER_SIZE iters, and on the final train iteration\n",
    "    if it % LOG_ITER_SIZE == 0 or it == NUM_ITERS-1:\n",
    "        print(\"Logging for epoch\", epoch)\n",
    "        dq.set_epoch(epoch)\n",
    "        train_probs = classifier.predict_proba(train_embeddings)\n",
    "        test_probs = classifier.predict_proba(test_embeddings)\n",
    "\n",
    "        # Again, we extract the model's embeddings and log those instead\n",
    "        model_train_embs = get_deepest_embeddings(classifier, train_embeddings)\n",
    "        model_test_embs = get_deepest_embeddings(classifier, test_embeddings)\n",
    "\n",
    "        dq.log_model_outputs(\n",
    "            embs=model_train_embs, \n",
    "            probs=train_probs, \n",
    "            ids=df_train[\"id\"].tolist(),\n",
    "            split=\"train\",\n",
    "        )\n",
    "        dq.log_model_outputs(\n",
    "            embs=model_test_embs, \n",
    "            probs=test_probs, \n",
    "            ids=df_test[\"id\"].tolist(),\n",
    "            split=\"test\",\n",
    "        )\n",
    "        epoch += 1\n",
    "\n",
    "dq.set_labels_for_run(sorted(df_train[label_col].unique()))\n",
    "dq.finish(create_data_embs=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb02d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
