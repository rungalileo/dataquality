# üîç Glossary

### DEP Score

A per sample holistic data quality score to identify samples in the dataset contributing to low or high model performance i.e. ‚Äòpulling‚Äô the model up or down respectively. In other words, the DEP score measures the potential for "misfit" of an observation to the given model. [Read More](galileo-product-features/galileo-data-error-potential-dep.md#dep-score-calculation)

### Hard for the model

The subset of data samples with highest DEP scores, thereby "hard" for the model to learn from during training or "hard" for the model to make predictions on at test time. These samples can be hard due to one or more of the following reasons: _boundary samples_, _noisy / corrupt samples_, _mislabelled samples_, _misclassified samples_, _out-of-distribution samples_ etc. [Read More](galileo-product-features/hard-easy-misclassified-subsets.md#hard-subset)

### Easy for the model

The subset of data samples with lowest DEP scores, thereby "easy" for the model to learn from during training, or "easy" for the model to make predictions on at test time. Typically these "easy" samples are clean, noise free data samples that the model had no issues training/predicting on. [Read More](galileo-product-features/hard-easy-misclassified-subsets.md#easy-subset)&#x20;

### Gold

The ground truth label of a sample as specified by the user. In other words, the target label used by the model for a sample.&#x20;

### Pred

The predicted label of a sample as specified by the model. In other words, the label with highest prediction probability by the model.&#x20;

### Label

Use interchangeably with `Gold`, and is the ground truth of a sample as specified by the user. In other words, the target used by the model for a sample.&#x20;

### Task

In a `text_multi_label` run, the task corresponds to the task your model is making a prediction for. For example:

```
input: I can't believe today is the day!
outputs: task happiness: true, task nervousness: true, task anger: false 
```

In this case, your tasks are `happiness`, `nervousness`, and `anger`

### Task Type

The particular modeling exercise your model is working towards. Some task types in Galileo:

* `text_classification`
* `text_multi_label`
* `text_ner`&#x20;

