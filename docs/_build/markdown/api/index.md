# Reference


* [PyTorch (dataquality.integrations.torch)](dataquality.md)


    * [`watch()`](dataquality.md#dataquality.integrations.torch.watch)


* [Transformers (dataquality.integrations.transformers_trainer)](dataquality.md#transformers-dataquality-integrations-transformers-trainer)


    * [`watch()`](dataquality.md#dataquality.integrations.transformers_trainer.watch)


* [Spacy (dataquality.integrations.spacy)](dataquality.md#spacy-dataquality-integrations-spacy)


    * [`watch()`](dataquality.md#dataquality.integrations.spacy.watch)


* [Keras Experimental (dataquality.integrations.experimental.keras)](dataquality.md#keras-experimental-dataquality-integrations-experimental-keras)


    * [`watch()`](dataquality.md#dataquality.integrations.experimental.keras.watch)


* [Keras (dataquality.integrations.keras)](dataquality.md#keras-dataquality-integrations-keras)


    * [`DataQualityCallback`](dataquality.md#dataquality.integrations.keras.DataQualityCallback)


    * [`DataQualityLoggingLayer`](dataquality.md#dataquality.integrations.keras.DataQualityLoggingLayer)


    * [`add_ids_to_numpy_arr()`](dataquality.md#dataquality.integrations.keras.add_ids_to_numpy_arr)


    * [`add_sample_ids()`](dataquality.md#dataquality.integrations.keras.add_sample_ids)


* [dataquality](dataquality.md#module-dataquality)


    * [`auto()`](dataquality.md#dataquality.auto)


    * [`finish()`](dataquality.md#dataquality.finish)


    * [`init()`](dataquality.md#dataquality.init)


    * [`log_data_sample()`](dataquality.md#dataquality.log_data_sample)


    * [`log_dataset()`](dataquality.md#dataquality.log_dataset)


    * [`log_model_outputs()`](dataquality.md#dataquality.log_model_outputs)


    * [`login()`](dataquality.md#dataquality.login)


    * [`set_epoch()`](dataquality.md#dataquality.set_epoch)


    * [`set_labels_for_run()`](dataquality.md#dataquality.set_labels_for_run)


    * [`set_split()`](dataquality.md#dataquality.set_split)


## Autogenerated dataquality documentation

# PyTorch (dataquality.integrations.torch)


### watch(model, dataloaders=[], last_hidden_state_layer=None, embedding_dim=None, logits_dim=None, classifier_layer=None, embedding_fn=None, logits_fn=None, unpatch_on_start=True)
wraps a PyTorch model and optionally dataloaders to log the
embeddings and logits to [Galileo]([https://www.rungalileo.io/](https://www.rungalileo.io/)).

```python
dq.log_dataset(train_dataset, split="train")
train_dataloader = torch.utils.data.DataLoader()
model = TextClassificationModel(num_labels=len(train_dataset.list_of_labels))
watch(model, [train_dataloader,test_dataloader])
for epoch in range(NUM_EPOCHS):
    dq.set_epoch_and_split(epoch,"training")
    train()
    dq.set_split("validate")
    validate()
dq.finish()
```


* **Parameters**

    
    * **model** (`Module`) -- Pytorch Model to be wrapped


    * **dataloaders** (`Optional`[`List`[`DataLoader`]]) -- List of dataloaders to be wrapped


    * **last_hidden_state_layer** (`Union`[`Module`, `str`, `None`]) -- Layer to extract the embeddings from


    * **embedding_dim** (`Union`[`str`, `int`, `slice`, `Tensor`, `List`, `Tuple`, `None`]) -- Dimension of the embeddings for example "[:, 0]"


to remove the cls token
:type logits_dim: `Union`[`str`, `int`, `slice`, `Tensor`, `List`, `Tuple`, `None`]
:param logits_dim: Dimension to extract the logits for example in NER
"[:,1:,:]"
:rtype: `None`
:return: None



```
``
```



```
`
```

{eval-rst}
# Transformers (dataquality.integrations.transformers_trainer)


```
``
```



```
`
```

{eval-rst}
.. autofunction:: dataquality.integrations.transformers_trainer.watch

# Spacy (dataquality.integrations.spacy)


### watch(nlp)
Stores the nlp object before calling watch on the ner component within it

We need access to the nlp object so that during training we can capture the
model's predictions over the raw text by running nlp("user's text") and looking
at the results


* **Parameters**

    **nlp** (`Language`) -- The spacy nlp Language component.



* **Return type**

    `None`



* **Returns**

    None


# Keras Experimental (dataquality.integrations.experimental.keras)


### watch(model, layer=None, seed=42)
Watch a model and log the inputs and outputs of a layer.
:type model: `Layer`
:param model: The model to watch
:type layer: `Optional`[`Any`]
:param layer: The layer to watch, if None the classifier layer is used
:type seed: `int`
:param seed: The seed to use for the model


* **Return type**

    `None`


# Keras (dataquality.integrations.keras)


* **members**



* **show-inheritance**


# dataquality

dataquality


* **members**

    init, log_dataset, set_labels_for_run, set_split, set_epoch, finish, login, auto, log_data_sample,log_image_dataset, log_model_outputs, logout



* **show-inheritance**
