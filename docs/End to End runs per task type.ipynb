{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579f0cbf",
   "metadata": {},
   "source": [
    "## End to end examples logging data to Galileo for Text Classification, MLTC, and NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27921069",
   "metadata": {},
   "source": [
    "### For understanding the client and how to get started, see the [Dataquality Demo](./Dataquality-Client-Demo.ipynb)\n",
    "### Check out the full documentation [here](https://rungalileo.gitbook.io/galileo/getting-started)\n",
    "### To see real end-to-end notebooks training real ML models, see [here](https://drive.google.com/drive/folders/17-cHuRzXIpWaD8rYwy69RMQr__HiAiDk?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b0c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Local\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['GALILEO_CONSOLE_URL']=\"http://localhost:8088\"\n",
    "os.environ[\"GALILEO_USERNAME\"]=\"user@example.com\"\n",
    "os.environ[\"GALILEO_PASSWORD\"]=\"Th3secret_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe0711c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dataquality as dq\n",
    "dq.configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098fd219",
   "metadata": {},
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13574b3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "from uuid import uuid4\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "\n",
    "BATCH_SIZE=16\n",
    "EMB_DIM=768\n",
    "NUM_EPOCHS=1\n",
    "\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset=\"train\", remove=('headers', 'footers', 'quotes'))\n",
    "dataset = pd.DataFrame()\n",
    "dataset[\"text\"] = newsgroups.data\n",
    "label_ind = newsgroups.target_names\n",
    "dataset[\"label\"] = [label_ind[i] for i in newsgroups.target]\n",
    "dataset[\"id\"] = list(range(len(dataset)))\n",
    "\n",
    "dataset = dataset[:200]\n",
    "\n",
    "\n",
    "def generate_random_embeddings(batch_size: int, emb_dims: int) -> np.ndarray:\n",
    "    return np.random.rand(batch_size, emb_dims)\n",
    "\n",
    "\n",
    "def generate_random_probabilities(batch_size: int, num_classes: int) -> np.ndarray:\n",
    "    probs = np.random.rand(batch_size, num_classes)\n",
    "    return probs / probs.sum(axis=-1).reshape(-1, 1)  # Normalize to sum to 1\n",
    "\n",
    "\n",
    "t_start = time.time()\n",
    "dq.set_labels_for_run(dataset[\"label\"].unique())\n",
    "\n",
    "print(\"Logging input data\")\n",
    "for split in [\"training\", \"test\"]:\n",
    "    dq.log_dataset(dataset, split=split)\n",
    "    \n",
    "print(\"Done\")\n",
    "print(f\"Input logging took {time.time() - t_start} seconds\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Logging model outputs\")\n",
    "t_start = time.time()\n",
    "num_classes = dataset[\"label\"].nunique()\n",
    "# Simulates model training loop\n",
    "for epoch_idx in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch_idx}\")\n",
    "    print('-'*100)\n",
    "    for split in [\"training\", \"test\"]:\n",
    "        print(split.capitalize())\n",
    "        dq.set_split(split)\n",
    "        for i in tqdm(range(0, len(dataset), BATCH_SIZE)):\n",
    "            batch = dataset[i : i + BATCH_SIZE]\n",
    "            embeddings = generate_random_embeddings(len(batch), EMB_DIM)\n",
    "            probs = generate_random_probabilities(len(batch), num_classes)\n",
    "            dq.log_model_outputs(\n",
    "                embs=embeddings,\n",
    "                probs=probs,\n",
    "                epoch=epoch_idx,\n",
    "                ids=batch[\"id\"],\n",
    "            )\n",
    "    print('-'*100,end=\"\\n\\n\")\n",
    "            \n",
    "print(\"Done\")\n",
    "\n",
    "time_spent = time.time() - t_start\n",
    "print(f\"Logging output took {time_spent} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ad827-21fb-499e-8926-e6c3e4ba7f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dq.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4684dd5",
   "metadata": {},
   "source": [
    "## Multi Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f17ab5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from random import choice\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dq.init(\"text_multi_label\", \"test-mltc-run\")\n",
    "dq.set_labels_for_run([[\"not \"+_label, _label] for _label in ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult','identity_hate']]) \n",
    "dq.set_tasks_for_run(['task_0', 'task_1', 'task_2', 'task_3', 'task_4', 'task_5'])\n",
    "\n",
    "n = 5000\n",
    "\n",
    "texts: List[str] = [f\"text sample {i}\" for i in range(n)]\n",
    "\n",
    "labels: List[str] = [\n",
    "    [choice(i) for i in dq.get_data_logger().logger_config.labels]\n",
    "    for _ in range(n)\n",
    "]\n",
    "\n",
    "ids = list(range(n))\n",
    "\n",
    "\n",
    "dq.log_data_samples(texts=texts, task_labels=labels, ids=ids, split=\"training\")\n",
    "dq.log_data_samples(texts=texts, task_labels=labels, ids=ids, split=\"test\")\n",
    "dq.log_data_samples(texts=texts, task_labels=labels, ids=ids, split=\"validation\")\n",
    "\n",
    "for split in [\"training\", \"test\", \"validation\"]:\n",
    "    for epoch in range(5):\n",
    "        emb=np.random.rand(n, 768)\n",
    "        logits=[[np.random.rand(2)] * 6] * n\n",
    "        ids=list(range(n))\n",
    "        \n",
    "        for i in range(0, n, 32):\n",
    "            dq.log_model_outputs(\n",
    "                embs=emb[i:i+5],\n",
    "                logits=logits[i:i+5],\n",
    "                ids=ids[i:i+5],\n",
    "                split=split,\n",
    "                epoch=epoch\n",
    "            )\n",
    "\n",
    "dq.finish()\n",
    "df_train, df_test, df_val = see_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82cc51",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ba254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataquality.schemas.task_type import TaskType\n",
    "from dataquality import config \n",
    "from uuid import uuid4\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "dq.init(\"text_ner\", \"test-ner-run\")\n",
    "\n",
    "\n",
    "def log_inputs():\n",
    "    text_inputs = ['what movies star bruce willis', 'show me films with drew barrymore from the 1980s', 'what movies starred both al pacino and robert deniro', 'find me all of the movies that starred harold ramis and bill murray', 'find me a movie with a quote about baseball in it']\n",
    "    tokens = [[(0, 4), (5, 11), (12, 16), (17, 22), (17, 22), (23, 29), (23, 29)], [(0, 4), (5, 7), (8, 13), (14, 18), (19, 23), (24, 33), (24, 33), (24, 33), (34, 38), (39, 42), (43, 48)], [(0, 4), (5, 11), (12, 19), (20, 24), (25, 27), (28, 34), (28, 34), (28, 34), (35, 38), (39, 45), (39, 45), (46, 52), (46, 52)], [(0, 4), (5, 7), (8, 11), (12, 14), (15, 18), (19, 25), (26, 30), (31, 38), (39, 45), (39, 45), (39, 45), (46, 51), (46, 51), (52, 55), (56, 60), (61, 67), (61, 67), (61, 67)], [(0, 4), (5, 7), (8, 9), (10, 15), (16, 20), (21, 22), (23, 28), (29, 34), (35, 43), (44, 46), (47, 49)]]\n",
    "    gold_spans = [[{'start': 17, 'end': 29, 'label': 'ACTOR'}], [{'start': 19, 'end': 33, 'label': 'ACTOR'}, {'start': 43, 'end': 48, 'label': 'YEAR'}], [{'start': 25, 'end': 34, 'label': 'ACTOR'}, {'start': 39, 'end': 52, 'label': 'ACTOR'}], [{'start': 39, 'end': 51, 'label': 'ACTOR'}, {'start': 56, 'end': 67, 'label': 'ACTOR'}], []]\n",
    "    ids = [0, 1, 2, 3, 4]\n",
    "\n",
    "    labels = ['[PAD]', '[CLS]', '[SEP]', 'O', 'B-ACTOR', 'I-ACTOR', 'B-YEAR', 'B-TITLE', 'B-GENRE', 'I-GENRE', 'B-DIRECTOR', 'I-DIRECTOR', 'B-SONG', 'I-SONG', 'B-PLOT', 'I-PLOT', 'B-REVIEW', 'B-CHARACTER', 'I-CHARACTER', 'B-RATING', 'B-RATINGS_AVERAGE', 'I-RATINGS_AVERAGE', 'I-TITLE', 'I-RATING', 'B-TRAILER', 'I-TRAILER', 'I-REVIEW', 'I-YEAR']\n",
    "    dq.set_labels_for_run(labels)\n",
    "    dq.set_tagging_schema(\"BIO\")\n",
    "    dq.log_data_samples(texts=text_inputs, text_token_indices=tokens, ids=ids, gold_spans=gold_spans, split=\"training\")\n",
    "    dq.log_data_samples(texts=text_inputs, text_token_indices=tokens, ids=ids, gold_spans=gold_spans, split=\"validation\")\n",
    "    dq.log_data_samples(texts=text_inputs, text_token_indices=tokens, ids=ids, gold_spans=gold_spans, split=\"test\")\n",
    "\n",
    "def log_outputs():\n",
    "    num_classes = 28\n",
    "    embs = [np.random.rand(119, 768) for _ in range(5)]\n",
    "    logits= [np.random.rand(119, 28) for _ in range(5)]                                      \n",
    "    ids= list(range(5))\n",
    "    for epoch in tqdm(range(6)):\n",
    "        for split in [\"training\", \"test\", \"validation\"]:\n",
    "            dq.log_model_outputs(\n",
    "                embs=embs, logits=logits, ids=ids, split=split, epoch=epoch\n",
    "            )\n",
    "    \n",
    "def finish():\n",
    "    dq.finish()\n",
    "    \n",
    "    \n",
    "def runit():\n",
    "    log_inputs()\n",
    "    log_outputs()\n",
    "    finish()\n",
    "    \n",
    "runit()\n",
    "df_train, df_test, df_val = see_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
