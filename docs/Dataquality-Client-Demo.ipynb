{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7081078",
   "metadata": {},
   "source": [
    "# Welcome to the dataquality client demo\n",
    "\n",
    "### This will be a brief introduction to how the client works and a bit under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9716a0d8",
   "metadata": {},
   "source": [
    "## Installing\n",
    "\n",
    "You can currently install dataquality from pypi\n",
    "`pip install dataquality`\n",
    "\n",
    "But for development, you may want to install it from github. This will give you the latest changes in master\n",
    "\n",
    "`pip install git+https://www.github.com/rungalileo/dataquality.git`\n",
    "\n",
    "You can also clone the repo and install from a path. This is recommended for development\n",
    "\n",
    "`pip install /path/to/dataquality/directory`\n",
    "\n",
    "**(It's good to restart the kernel after an install)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94b276a-bcec-448e-8f29-515cd7354cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/anthcor/dataquality/docs\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5afe1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8e7ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have cloned the dataquality repo and are running this from the docs folder, you can run this\n",
    "!pip install -q ../dataquality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f0b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or install latest from main\n",
    "!pip install -qqq git+https://www.github.com/rungalileo/dataquality.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c50925",
   "metadata": {},
   "source": [
    "## Components\n",
    "\n",
    "The data quality client is currently very simple. It has just a few components:\n",
    "\n",
    "* logging - the inputs and outputs to your model\n",
    "* config - the urls, usernames, and passwords to interact with the server\n",
    "* init - how you start a new project/run\n",
    "* finish - how you end your run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234111dd",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "To get started, simply `import dataquality`<br>\n",
    "If your environment variables are set, your import will pass through. If not, you will be prompted for some url and config variables.<br>\n",
    "\n",
    "To bypass the prompt, set the following environment variables\n",
    "* `GALILEO_CONSOLE_URL`\n",
    "\n",
    "If you have your server (api, minio, mysql) running locally for development, the following will work\n",
    "```\n",
    "import os\n",
    "\n",
    "os.environ['GALILEO_CONSOLE_URL']=\"http://localhost\"\n",
    "```\n",
    "\n",
    "If you don't set these environment variables, the client will prompt you for the fields (assuming you're running from the newest code).\n",
    "\n",
    "### How do I get everything running locally??\n",
    "\n",
    "See our [CONTRIBUTING](https://github.com/rungalileo/api/blob/main/CONTRIBUTING.md) doc\n",
    "(When running the API, use the `./scripts/run-gunicorn.sh` - you don't need all of them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be42940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['GALILEO_CONSOLE_URL']=\"http://localhost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9197b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dev cluster, run this cell\n",
    "\n",
    "# import os\n",
    "# os.environ['GALILEO_CONSOLE_URL']=\"https://console.dev.rungalileo.io\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df5b2ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataquality as dq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c440db27",
   "metadata": {},
   "source": [
    "## Logging in\n",
    "\n",
    "Once you have dataquality imported, you can log into your server and start logging data<br>\n",
    "\n",
    "To log in, you can call `dataquality.login()` <br>\n",
    "This will prompt you for your auth method, email, and password. You can skip this prompt with the following environment variables:\n",
    "\n",
    "* `GALILEO_USERNAME`\n",
    "* `GALILEO_PASSWORD`\n",
    "\n",
    "### How do I create a user?\n",
    "\n",
    "If you are running everything locally, you can do the following to create the admin user.\n",
    "\n",
    "**Note: If the admin user already exists, you cannot create another one.**\n",
    "\n",
    "```\n",
    "import requests\n",
    "\n",
    "data={\n",
    "  \"email\": \"me@rungalileo.io\",\n",
    "  \"first_name\": \"Me\",\n",
    "  \"last_name\": \"Me\",\n",
    "  \"username\": \"Galileo\",\n",
    "  \"auth_method\": \"email\",\n",
    "  \"password\": \"Th3secret_\"\n",
    "}\n",
    "\n",
    "r = requests.post('http://localhost:8088/users/admin', json=data)\n",
    "r.json()\n",
    "```\n",
    "\n",
    "Then set your env vars\n",
    "```\n",
    "import os\n",
    "\n",
    "os.environ[\"GALILEO_USERNAME\"]=\"{r.json()['email']}\"\n",
    "os.environ[\"GALILEO_PASSWORD\"]=\"{r.json()['password']}\"\n",
    "```\n",
    "\n",
    "If you don't set these environment variables, the client will prompt you for the fields (assuming you're running from the newest code).\n",
    "\n",
    "Now login\n",
    "\n",
    "```\n",
    "dataquality.login()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29192d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# pwd = \"MyPassword!123\"\n",
    "\n",
    "# data={\n",
    "#   \"email\": \"me@rungalileo.io\",\n",
    "#   \"first_name\": \"Me\",\n",
    "#   \"last_name\": \"Me\",\n",
    "#   \"username\": \"Galileo\",\n",
    "#   \"auth_method\": \"email\",\n",
    "#   \"password\": pwd\n",
    "# }\n",
    "\n",
    "# r = requests.post(f'{dq.config.api_url}/users/admin', json=data)\n",
    "\n",
    "# import os\n",
    "\n",
    "os.environ[\"GALILEO_USERNAME\"]=f\"user@example.com\"\n",
    "os.environ[\"GALILEO_PASSWORD\"]=\"Th3secret_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b6cf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° http://localhost:8088\n",
      "üî≠ Logging you into Galileo\n",
      "\n",
      "üëÄ Found auth method email set via env, skipping prompt.\n",
      "üöÄ You're logged in to Galileo as user@example.com!\n"
     ]
    }
   ],
   "source": [
    "dq.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3224a",
   "metadata": {},
   "source": [
    "## Start my project/run\n",
    "\n",
    "Now you can start using the tool with `dataquality.init()`<br>\n",
    "\n",
    "You **must** provide a `task_type` when calling `init`\n",
    "* A task type describes the kind of modeling you are doing (text classification, multi-label, NER etc).\n",
    "* Currently the only available task is \"text_classification\"\n",
    "\n",
    "You can optionally provide a project name for this run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a084759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dq.init?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "803b260e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ú® Initializing public project excellent_violet_landfowl\n",
      "üèÉ‚Äç‚ôÇÔ∏è Starting run melodic_fuchsia_fish\n",
      "üõ∞ Created project, excellent_violet_landfowl, and new run, melodic_fuchsia_fish.\n"
     ]
    }
   ],
   "source": [
    "task = \"text_classification\"\n",
    "# Base case\n",
    "dq.init(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf4bc01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí≠ Project a_new_project was not found.\n",
      "‚ú® Initializing public project a_new_project\n",
      "üèÉ‚Äç‚ôÇÔ∏è Starting run roasted_yellow_hippopotamus\n"
     ]
    }
   ],
   "source": [
    "# New project, unset run (new)\n",
    "dq.init(task_type=task, project_name=\"a_new_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "800a72dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Retrieved project, a_new_project, and starting a new run\n",
      "üèÉ‚Äç‚ôÇÔ∏è Starting run miniature_green_sailfish\n",
      "üõ∞ Connected to project, a_new_project, and created run, miniature_green_sailfish.\n"
     ]
    }
   ],
   "source": [
    "# Existing project, unset run (new)\n",
    "dq.init(task_type=task, project_name=\"a_new_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb2cb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Retrieving run from existing project, a_new_project\n",
      "üèÉ‚Äç‚ôÇÔ∏è Starting run a_new_run\n",
      "üõ∞ Connected to project, a_new_project and created new run, a_new_run.\n"
     ]
    }
   ],
   "source": [
    "# Existing project, new run\n",
    "dq.init(task_type=task, project_name=\"a_new_project\", run_name=\"a_new_run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "857160d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Retrieving run from existing project, a_new_project\n",
      "üõ∞ Connected to project, a_new_project, and run, a_new_run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthcor/dataquality/.venv/lib/python3.9/site-packages/dataquality/core/init.py:164: UserWarning: Run: a_new_project/a_new_run already exists! The existing run will get overwritten on call to finish()!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Existing project, existing run\n",
    "dq.init(task_type=task, project_name=\"a_new_project\", run_name=\"a_new_run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70efebb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí≠ Project a_new_project2 was not found.\n",
      "‚ú® Initializing public project a_new_project2\n",
      "üèÉ‚Äç‚ôÇÔ∏è Starting run a_new_run2\n",
      "üõ∞ Created project, a_new_project2, and new run, a_new_run2.\n"
     ]
    }
   ],
   "source": [
    "# New project, new run\n",
    "dq.init(task_type=task, project_name=\"a_new_project2\", run_name=\"a_new_run2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb849b7",
   "metadata": {},
   "source": [
    "## Log to my project/run\n",
    "\n",
    "Now that you've started your run, all you need to do is log data to it.<br>\n",
    "\n",
    "All you need to do is call the `dataquality.log_data_samples` and `dataquality.log_model_outputs` functions.\n",
    "\n",
    "`dataquality.log_data_samples` knows which task you are logging for, and accepts the proper arguments.\n",
    "For \"text_classification\" it is expecting\n",
    "* texts - list of strings indicating the text input\n",
    "* labels - list of strings indicating the labels\n",
    "* split - string indicating the data split (training, validation, test)\n",
    "* ids - list of ints indicating the id of each row.\n",
    "  * NOTE: This ID must match the output ID in log_model_outputs in order to join them for analysis\n",
    "\n",
    "`dataquality.log_model_outputs` also knows which task you are logging for.\n",
    "For \"text_classification\" it is expecting\n",
    "* emb - list of lists of embedding values for a given text input\n",
    "* probs - list of list of probabilities of the confidence per class\n",
    "* split - string indicating the data split (training, validation, test)\n",
    "* epoch - int indicating the training/test/validation epoch for the input\n",
    "* ids - list of ints indicating the matching id to the input row\n",
    "  * NOTE: This ID must match the output ID in log_model_outputs in order to join them for analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d086f3dd",
   "metadata": {},
   "source": [
    "### log some data\n",
    "\n",
    "We use the `log_data_samples` and `log_model_outputs` to log our metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1db00ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ú® Initializing public project excited_chocolate_parakeet\n",
      "üèÉ‚Äç‚ôÇÔ∏è Starting run unaware_rose_catfish\n",
      "üõ∞ Created project, excited_chocolate_parakeet, and new run, unaware_rose_catfish.\n"
     ]
    }
   ],
   "source": [
    "dq.init(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2af2357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting input data [########################################] 100.00% elapsed time  :     0.00s =  0.0m =  0.0h\n",
      "Appending input data [########################################] 100.00% elapsed time  :     0.00s =  0.0m =  0.0h\n",
      " "
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset=\"train\", remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "dataset = pd.DataFrame()\n",
    "dataset[\"text\"] = newsgroups.data\n",
    "label_ind = newsgroups.target_names\n",
    "dataset[\"label\"] = [label_ind[i] for i in newsgroups.target]\n",
    "dataset = dataset[:100]\n",
    "\n",
    "# Add IDs to the dataset for logging\n",
    "dataset[\"id\"] = list(range(len(dataset)))\n",
    "\n",
    "dq.log_dataset(dataset, split=\"train\")\n",
    "dq.log_dataset(dataset, split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6194d70e",
   "metadata": {},
   "source": [
    "\n",
    "## We validate data before logging\n",
    "\n",
    "#### See what happens with invalid data (not enough IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecc3949c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "labels and text must be the same length, but got(labels, text) (3, 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Labels and text inputs dont match in shape\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_data_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dataquality/.venv/lib/python3.9/site-packages/dataquality/utils/helpers.py:20\u001b[0m, in \u001b[0;36mcheck_noop.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(GALILEO_DISABLED):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dataquality/.venv/lib/python3.9/site-packages/dataquality/core/log.py:71\u001b[0m, in \u001b[0;36mlog_data_samples\u001b[0;34m(texts, ids, meta, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m     68\u001b[0m     [config\u001b[38;5;241m.\u001b[39mtask_type, config\u001b[38;5;241m.\u001b[39mcurrent_project_id, config\u001b[38;5;241m.\u001b[39mcurrent_run_id]\n\u001b[1;32m     69\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must call dataquality.init before logging data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m data_logger \u001b[38;5;241m=\u001b[39m get_data_logger()\n\u001b[0;32m---> 71\u001b[0m \u001b[43mdata_logger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_data_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dataquality/.venv/lib/python3.9/site-packages/dataquality/loggers/data_logger/text_classification.py:154\u001b[0m, in \u001b[0;36mTextClassificationDataLogger.log_data_samples\u001b[0;34m(self, texts, ids, labels, split, inference_name, meta, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_name \u001b[38;5;241m=\u001b[39m inference_name\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta \u001b[38;5;241m=\u001b[39m meta \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dataquality/.venv/lib/python3.9/site-packages/dataquality/loggers/data_logger/base_data_logger.py:80\u001b[0m, in \u001b[0;36mBaseGalileoDataLogger.log\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124;03m\"\"\"Writes input data to disk in .galileo/logs\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    If input data already exist, append new data to existing input file\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     write_input_dir \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBaseGalileoLogger\u001b[38;5;241m.\u001b[39mLOG_FILE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mcurrent_project_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mcurrent_run_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m     )\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(write_input_dir):\n",
      "File \u001b[0;32m~/dataquality/.venv/lib/python3.9/site-packages/dataquality/loggers/data_logger/text_classification.py:340\u001b[0m, in \u001b[0;36mTextClassificationDataLogger.validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m label_len \u001b[38;5;129;01mand\u001b[39;00m text_len, (\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must log both text and labels for split \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Text samples logged:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, labels logged:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m     )\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m text_len \u001b[38;5;241m==\u001b[39m label_len, (\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels and text must be the same length, but got\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(labels, text) (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    343\u001b[0m     )\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m id_len \u001b[38;5;241m==\u001b[39m text_len, (\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIds exists but are not the same length as text and labels. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ids, text) (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mid_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m )\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_metadata(batch_size\u001b[38;5;241m=\u001b[39mtext_len)\n",
      "\u001b[0;31mAssertionError\u001b[0m: labels and text must be the same length, but got(labels, text) (3, 100)"
     ]
    }
   ],
   "source": [
    "# Labels and text inputs dont match in shape\n",
    "dq.log_data_samples(texts=dataset['text'], labels=dataset['label'][:3], split=\"train\", ids=list(range(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84c5560a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate fake model outputs\n",
    "def log_fake_data(log_num: int = 0):\n",
    "    # Ensure unique IDs\n",
    "    # Because we're going to call this twice, we need the other dataset rows for the second call, so /2\n",
    "    num_rows = len(dataset) // 2 \n",
    "        \n",
    "    embs = np.random.rand(num_rows, 800)\n",
    "    logits = np.random.rand(num_rows, 20)\n",
    "    for split in ['test','train']:\n",
    "        epoch = 0\n",
    "        \n",
    "        r = range(num_rows*log_num, num_rows*(log_num+1))\n",
    "        ids = list(r)\n",
    "        dq.log_model_outputs(embs=embs, logits=logits, split=split, epoch=epoch, ids=ids)\n",
    "\n",
    "log_fake_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ae89fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/Users/anthcor/.galileo/logs/42ce0d80-fde2-4fd8-886b-f002fb5f14de/d816e0dc-849d-4e8d-8091-0b762f8c9cd0\u001b[00m\r\n",
      "‚îú‚îÄ‚îÄ input_data.arrow\r\n",
      "‚îú‚îÄ‚îÄ \u001b[01;34mtest\u001b[00m\r\n",
      "‚îÇ¬†¬† ‚îî‚îÄ‚îÄ \u001b[01;34m0\u001b[00m\r\n",
      "‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ 90c8553e6986.hdf5\r\n",
      "‚îî‚îÄ‚îÄ \u001b[01;34mtraining\u001b[00m\r\n",
      "    ‚îî‚îÄ‚îÄ \u001b[01;34m0\u001b[00m\r\n",
      "        ‚îî‚îÄ‚îÄ 689fe0b90f8a.hdf5\r\n",
      "\r\n",
      "4 directories, 3 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree ~/.galileo/logs/{dq.config.current_project_id}/{dq.config.current_run_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af65e13",
   "metadata": {},
   "source": [
    "### What happened?\n",
    "\n",
    "When you call `log_batch_input_data` you are logging the input data for this training job. This would typically be run once (per split).<br>\n",
    "\n",
    "Then, as you train your model in batches, each call to `log_model_outputs` takes the data in that batch, joins it to the input data, and stores it in 3 files, data, emb, and prob.<br>\n",
    "\n",
    "If we were to log another fake dataset to this, we'd see another file in each dir (under the epoch we set).\n",
    "\n",
    "The file names in each subdir will match so we can join them at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61e4875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fake_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a55f02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/Users/anthcor/.galileo/logs/42ce0d80-fde2-4fd8-886b-f002fb5f14de/d816e0dc-849d-4e8d-8091-0b762f8c9cd0\u001b[00m\r\n",
      "‚îú‚îÄ‚îÄ input_data.arrow\r\n",
      "‚îú‚îÄ‚îÄ \u001b[01;34mtest\u001b[00m\r\n",
      "‚îÇ¬†¬† ‚îî‚îÄ‚îÄ \u001b[01;34m0\u001b[00m\r\n",
      "‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ 90c8553e6986.hdf5\r\n",
      "‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ c9f0272c242f.hdf5\r\n",
      "‚îî‚îÄ‚îÄ \u001b[01;34mtraining\u001b[00m\r\n",
      "    ‚îî‚îÄ‚îÄ \u001b[01;34m0\u001b[00m\r\n",
      "        ‚îú‚îÄ‚îÄ 689fe0b90f8a.hdf5\r\n",
      "        ‚îî‚îÄ‚îÄ fc1358905b08.hdf5\r\n",
      "\r\n",
      "4 directories, 5 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree ~/.galileo/logs/{dq.config.current_project_id}/{dq.config.current_run_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a9d253",
   "metadata": {},
   "source": [
    "## Take a look at our logged model outputs\n",
    "\n",
    "Below is the model output data we've logged to test. You can see all of the values available across both logs<br>\n",
    "To see the training data, just change the variable to `training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaa8ae6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                             </th><th>data_schema_version  </th><th>emb                                                </th><th>epoch  </th><th>id  </th><th>pred  </th><th>prob                                               </th><th>split  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i> </td><td>1                    </td><td>&#x27;array([8.57106623e-01, 8.93980231e-01, 6.313378...</td><td>0      </td><td>0   </td><td>13    </td><td>&#x27;array([0.04859771, 0.05946847, 0.04279913, 0.05...</td><td>b&#x27;test&#x27;</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i> </td><td>1                    </td><td>&#x27;array([0.35334157, 0.65359292, 0.30023309, 0.33...</td><td>0      </td><td>1   </td><td>10    </td><td>&#x27;array([0.05875081, 0.07051047, 0.03753773, 0.03...</td><td>b&#x27;test&#x27;</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>2</i> </td><td>1                    </td><td>&#x27;array([1.08380079e-01, 9.05909130e-01, 9.835939...</td><td>0      </td><td>2   </td><td>4     </td><td>&#x27;array([0.04596923, 0.07366717, 0.06822204, 0.05...</td><td>b&#x27;test&#x27;</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>3</i> </td><td>1                    </td><td>&#x27;array([0.85230045, 0.57928173, 0.34920781, 0.33...</td><td>0      </td><td>3   </td><td>3     </td><td>&#x27;array([0.04394911, 0.07299215, 0.0611209 , 0.07...</td><td>b&#x27;test&#x27;</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>4</i> </td><td>1                    </td><td>&#x27;array([0.19895986, 0.04940142, 0.04691344, 0.27...</td><td>0      </td><td>4   </td><td>14    </td><td>&#x27;array([0.03113366, 0.0478598 , 0.05287021, 0.05...</td><td>b&#x27;test&#x27;</td></tr>\n",
       "<tr><td>...                           </td><td>...                  </td><td>...                                                </td><td>...    </td><td>... </td><td>...   </td><td>...                                                </td><td>...    </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>95</i></td><td>1                    </td><td>&#x27;array([5.57126912e-01, 6.27893930e-01, 3.404685...</td><td>0      </td><td>95  </td><td>9     </td><td>&#x27;array([0.04180124, 0.06067209, 0.05874632, 0.07...</td><td>b&#x27;test&#x27;</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>96</i></td><td>1                    </td><td>&#x27;array([3.26800281e-01, 5.57304539e-02, 3.614219...</td><td>0      </td><td>96  </td><td>5     </td><td>&#x27;array([0.08142364, 0.05431067, 0.0339393 , 0.07...</td><td>b&#x27;test&#x27;</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>97</i></td><td>1                    </td><td>&#x27;array([0.48076435, 0.50786567, 0.51101304, 0.02...</td><td>0      </td><td>97  </td><td>0     </td><td>&#x27;array([0.07782885, 0.07363639, 0.05245695, 0.03...</td><td>b&#x27;test&#x27;</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>98</i></td><td>1                    </td><td>&#x27;array([1.91997988e-01, 6.01161071e-01, 7.477167...</td><td>0      </td><td>98  </td><td>13    </td><td>&#x27;array([0.04381874, 0.06332405, 0.0422959 , 0.05...</td><td>b&#x27;test&#x27;</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>99</i></td><td>1                    </td><td>&#x27;array([0.53637358, 0.82092425, 0.25872752, 0.61...</td><td>0      </td><td>99  </td><td>1     </td><td>&#x27;array([0.04473131, 0.07818253, 0.06559481, 0.03...</td><td>b&#x27;test&#x27;</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "#    data_schema_version    emb                                                  epoch    id    pred    prob                                                 split\n",
       "0    1                      'array([8.57106623e-01, 8.93980231e-01, 6.313378...  0        0     13      'array([0.04859771, 0.05946847, 0.04279913, 0.05...  b'test'\n",
       "1    1                      'array([0.35334157, 0.65359292, 0.30023309, 0.33...  0        1     10      'array([0.05875081, 0.07051047, 0.03753773, 0.03...  b'test'\n",
       "2    1                      'array([1.08380079e-01, 9.05909130e-01, 9.835939...  0        2     4       'array([0.04596923, 0.07366717, 0.06822204, 0.05...  b'test'\n",
       "3    1                      'array([0.85230045, 0.57928173, 0.34920781, 0.33...  0        3     3       'array([0.04394911, 0.07299215, 0.0611209 , 0.07...  b'test'\n",
       "4    1                      'array([0.19895986, 0.04940142, 0.04691344, 0.27...  0        4     14      'array([0.03113366, 0.0478598 , 0.05287021, 0.05...  b'test'\n",
       "...  ...                    ...                                                  ...      ...   ...     ...                                                  ...\n",
       "95   1                      'array([5.57126912e-01, 6.27893930e-01, 3.404685...  0        95    9       'array([0.04180124, 0.06067209, 0.05874632, 0.07...  b'test'\n",
       "96   1                      'array([3.26800281e-01, 5.57304539e-02, 3.614219...  0        96    5       'array([0.08142364, 0.05431067, 0.0339393 , 0.07...  b'test'\n",
       "97   1                      'array([0.48076435, 0.50786567, 0.51101304, 0.02...  0        97    0       'array([0.07782885, 0.07363639, 0.05245695, 0.03...  b'test'\n",
       "98   1                      'array([1.91997988e-01, 6.01161071e-01, 7.477167...  0        98    13      'array([0.04381874, 0.06332405, 0.0422959 , 0.05...  b'test'\n",
       "99   1                      'array([0.53637358, 0.82092425, 0.25872752, 0.61...  0        99    1       'array([0.04473131, 0.07818253, 0.06559481, 0.03...  b'test'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vaex\n",
    "from pathlib import Path\n",
    "\n",
    "split = \"test\"\n",
    "vaex.open(f'{Path.home()}/.galileo/logs/{dq.config.current_project_id}/{dq.config.current_run_id}/{split}/0/*.hdf5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48325087",
   "metadata": {},
   "source": [
    "## How do I see my results in the UI?\n",
    "\n",
    "Simply set your labels (`set_labels_for_run`) and call `finish()`\n",
    "\n",
    "Once called, the data will be joined together at a _per-epoch_ level, and added to minio, with one file for each `prob`, `emb`, and `data` per split/epoch. \n",
    "\n",
    "A job will be kicked off to process you data on the server, and after it's done you'll see your results in the UI\n",
    "\n",
    "#### Why do I need to set my labels?\n",
    "\n",
    "Since your model is simply outputting probabilities, we have no way to map the index of each prediction to the model output. Setting your labels enables us to map them so you can see the meaningful values in the UI.<br>\n",
    "\n",
    "If you have the UI running, you should see it at the URL returned.\n",
    "\n",
    "**Note:** Check out your local API logs to see the background job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbc218af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚òÅÔ∏è Uploading Data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4302319bcd4a3eabf2777e35592536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Combining batches for upload:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training (epoch=0):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9361ccbaa00747ee8feb070818b0efd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Combining batches for upload:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test (epoch=0):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Cleaning up\n",
      "Job default successfully submitted. Results will be available soon at http://127.0.0.1:3000/insights?projectId=42ce0d80-fde2-4fd8-886b-f002fb5f14de&runId=9541d893-bbe6-429c-b071-22aee032bb5e&split=training&taskType=0&depHigh=1&depLow=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'project_id': '42ce0d80-fde2-4fd8-886b-f002fb5f14de',\n",
       " 'run_id': '9541d893-bbe6-429c-b071-22aee032bb5e',\n",
       " 'job_name': 'default',\n",
       " 'labels': ['alt.atheism',\n",
       "  'comp.graphics',\n",
       "  'comp.os.ms-windows.misc',\n",
       "  'comp.sys.ibm.pc.hardware',\n",
       "  'comp.sys.mac.hardware',\n",
       "  'comp.windows.x',\n",
       "  'misc.forsale',\n",
       "  'rec.autos',\n",
       "  'rec.motorcycles',\n",
       "  'rec.sport.baseball',\n",
       "  'rec.sport.hockey',\n",
       "  'sci.crypt',\n",
       "  'sci.electronics',\n",
       "  'sci.med',\n",
       "  'sci.space',\n",
       "  'soc.religion.christian',\n",
       "  'talk.politics.guns',\n",
       "  'talk.politics.mideast',\n",
       "  'talk.politics.misc',\n",
       "  'talk.religion.misc'],\n",
       " 'task_type': 0,\n",
       " 'tasks': None,\n",
       " 'non_inference_logged': False,\n",
       " 'migration_name': None,\n",
       " 'message': 'Processing dataquality!',\n",
       " 'link': 'http://127.0.0.1:3000/insights?projectId=42ce0d80-fde2-4fd8-886b-f002fb5f14de&runId=9541d893-bbe6-429c-b071-22aee032bb5e&split=training&taskType=0&depHigh=1&depLow=0'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq.set_labels_for_run(newsgroups.target_names)\n",
    "dq.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d433bde",
   "metadata": {},
   "source": [
    "## That should take ~10-20 seconds to complete (if you are running the server locally)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa54659c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your logfile has been written to /Users/anthcor/.galileo/out/9541d893-bbe6-429c-b071-22aee032bb5e/out.log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/anthcor/.galileo/out/9541d893-bbe6-429c-b071-22aee032bb5e/out.log'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from time import sleep\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# for i in tqdm(range(20)):\n",
    "#     sleep(1)\n",
    "dq.get_dq_log_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251892c5",
   "metadata": {},
   "source": [
    "### Now we can export our results to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d27cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataquality.schemas.split import Split\n",
    "from dataquality.clients.api import ApiClient\n",
    "import pandas as pd\n",
    "\n",
    "api_client = ApiClient()\n",
    "pname, rname = api_client.get_project_run_name()\n",
    "api_client.export_run(pname, rname, Split.training, \"training_data.csv\")\n",
    "\n",
    "pd.read_csv(\"training_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f2fd90",
   "metadata": {},
   "source": [
    "### (Local only) we can also read the data from minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "\n",
    "url = dq.config.minio_url\n",
    "client = Minio(url, 'minioadmin', 'minioadmin', secure=(':9000' not in url))\n",
    "p = dq.config.current_project_id\n",
    "r = dq.config.current_run_id\n",
    "client.fget_object('galileo-project-runs-results', f'{p}/{r}/training/data/data.hdf5', 'training_data.hdf5')\n",
    "client.fget_object('galileo-project-runs-results', f'{p}/{r}/test/data/data.hdf5', 'test_data.hdf5')\n",
    "\n",
    "display(vaex.open('training_data.hdf5'))\n",
    "\n",
    "display(vaex.open('test_data.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a536bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
