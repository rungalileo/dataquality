{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579f0cbf",
   "metadata": {},
   "source": [
    "## End to end examples logging data to Galileo for Text Classification, MLTC, and NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27921069",
   "metadata": {},
   "source": [
    "### For understanding the client and how to get started, see the [Dataquality Demo](./Dataquality-Client-Demo.ipynb)\n",
    "### Check out the full documentation [here](https://rungalileo.gitbook.io/galileo/getting-started)\n",
    "### To see real end-to-end notebooks training real ML models, see [here](https://drive.google.com/drive/folders/17-cHuRzXIpWaD8rYwy69RMQr__HiAiDk?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b0c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Local\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['GALILEO_CONSOLE_URL']=\"http://localhost:8088\"\n",
    "os.environ[\"GALILEO_USERNAME\"]=\"user@example.com\"\n",
    "os.environ[\"GALILEO_PASSWORD\"]=\"Th3secret_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe0711c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dataquality as dq\n",
    "dq.configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b357b36",
   "metadata": {},
   "source": [
    "***Helper function***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4092c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataquality import config\n",
    "import pandas as pd\n",
    "from dataquality.clients.api import ApiClient\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "api_client = ApiClient()\n",
    "\n",
    "\n",
    "def see_results(wait=True, body={}):\n",
    "    if wait:\n",
    "        print(\"Waiting for data to be processed\")\n",
    "        api_client.wait_for_run()\n",
    "\n",
    "    task_type = dq.config.task_type\n",
    "    proj = api_client.get_project(config.current_project_id)[\"name\"]\n",
    "    run = api_client.get_project_run(config.current_project_id, config.current_run_id)[\"name\"]\n",
    "    api_client.export_run(proj, run, \"training\", f\"{task_type}_training.csv\")\n",
    "    api_client.export_run(proj, run, \"test\", f\"{task_type}_test.csv\")\n",
    "    api_client.export_run(proj, run, \"validation\", f\"{task_type}_validation.csv\")\n",
    "    print(f\"Exported to {task_type}_training.csv, {task_type}_test.csv, and {task_type}_validation.csv\")\n",
    "    df_train = pd.read_csv(f\"{task_type}_training.csv\")\n",
    "    df_test = pd.read_csv(f\"{task_type}_test.csv\")\n",
    "    df_val = pd.read_csv(f\"{task_type}_validation.csv\")\n",
    "    print(\"Training\")\n",
    "    display(df_train)\n",
    "    print(\"\\nTest\")\n",
    "    display(df_test)\n",
    "    print(\"\\nValidation\")\n",
    "    display(df_val)\n",
    "    return df_train, df_test, df_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82cc51",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ba254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataquality.schemas.task_type import TaskType\n",
    "from dataquality import config \n",
    "from uuid import uuid4\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "dq.init(\"text_ner\", \"test-ner-proj\", \"test-ner-run\")\n",
    "\n",
    "\n",
    "def log_inputs():\n",
    "    text_inputs = ['what movies star bruce willis', 'show me films with drew barrymore from the 1980s', 'what movies starred both al pacino and robert deniro', 'find me all of the movies that starred harold ramis and bill murray', 'find me a movie with a quote about baseball in it']\n",
    "    tokens = [[(0, 4), (5, 11), (12, 16), (17, 22), (17, 22), (23, 29), (23, 29)], [(0, 4), (5, 7), (8, 13), (14, 18), (19, 23), (24, 33), (24, 33), (24, 33), (34, 38), (39, 42), (43, 48)], [(0, 4), (5, 11), (12, 19), (20, 24), (25, 27), (28, 34), (28, 34), (28, 34), (35, 38), (39, 45), (39, 45), (46, 52), (46, 52)], [(0, 4), (5, 7), (8, 11), (12, 14), (15, 18), (19, 25), (26, 30), (31, 38), (39, 45), (39, 45), (39, 45), (46, 51), (46, 51), (52, 55), (56, 60), (61, 67), (61, 67), (61, 67)], [(0, 4), (5, 7), (8, 9), (10, 15), (16, 20), (21, 22), (23, 28), (29, 34), (35, 43), (44, 46), (47, 49)]]\n",
    "    gold_spans = [[{'start': 17, 'end': 29, 'label': 'ACTOR'}], [{'start': 19, 'end': 33, 'label': 'ACTOR'}, {'start': 43, 'end': 48, 'label': 'YEAR'}], [{'start': 25, 'end': 34, 'label': 'ACTOR'}, {'start': 39, 'end': 52, 'label': 'ACTOR'}], [{'start': 39, 'end': 51, 'label': 'ACTOR'}, {'start': 56, 'end': 67, 'label': 'ACTOR'}], []]\n",
    "    ids = [0, 1, 2, 3, 4]\n",
    "\n",
    "    labels = ['[PAD]', '[CLS]', '[SEP]', 'O', 'B-ACTOR', 'I-ACTOR', 'B-YEAR', 'B-TITLE', 'B-GENRE', 'I-GENRE', 'B-DIRECTOR', 'I-DIRECTOR', 'B-SONG', 'I-SONG', 'B-PLOT', 'I-PLOT', 'B-REVIEW', 'B-CHARACTER', 'I-CHARACTER', 'B-RATING', 'B-RATINGS_AVERAGE', 'I-RATINGS_AVERAGE', 'I-TITLE', 'I-RATING', 'B-TRAILER', 'I-TRAILER', 'I-REVIEW', 'I-YEAR']\n",
    "    dq.set_labels_for_run(labels)\n",
    "    dq.set_tagging_schema(\"BIO\")\n",
    "    # dq.log_data_samples(texts=text_inputs, text_token_indices=tokens, ids=ids, gold_spans=gold_spans, split=\"training\")\n",
    "    # dq.log_data_samples(texts=text_inputs, text_token_indices=tokens, ids=ids, gold_spans=gold_spans, split=\"validation\")\n",
    "    dq.log_data_samples(texts=text_inputs, text_token_indices=tokens, ids=ids, split=\"inference\", inference_name=\"hi\")\n",
    "\n",
    "def log_outputs():\n",
    "    num_classes = 28\n",
    "    embs = [np.random.rand(119, 768) for _ in range(5)]\n",
    "    logits= [np.random.rand(119, 28) for _ in range(5)]                                      \n",
    "    ids= list(range(5))\n",
    "    for split in [\"inference\"]:\n",
    "        dq.log_model_outputs(\n",
    "            embs=embs, logits=logits, ids=ids, split=split, inference_name=\"hi\"\n",
    "        )\n",
    "    \n",
    "def finish():\n",
    "    dq.finish()\n",
    "    \n",
    "    \n",
    "def runit():\n",
    "    log_inputs()\n",
    "    log_outputs()\n",
    "    finish()\n",
    "    \n",
    "runit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
