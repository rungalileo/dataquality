{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9acac185",
   "metadata": {},
   "source": [
    "# Seq2Seq DQ Test Notebook\n",
    "\n",
    "In this notebook we test the dq client for **EncoderDecoder** models using simulated / fake data. The main intention is to battle test the different components of the client without training an actual model - i.e. optimizing for speed!\n",
    "\n",
    "Things that we want to test:\n",
    "1. Using the watch function - to set the tokenizer + generation_config\n",
    "2. Logging data (input + target outputs)\n",
    "3. Logging model outputs 1+ epoch\n",
    "4. Fake model generations - interestingly the best way to do this may be with a small validation dataset + a real LLM model. This depends a bit on design decisions around logging for generation.\n",
    "\n",
    "NOTE: For a first pass we work with just a training dataset\n",
    "\n",
    "Let's get testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6053a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9074b1ff",
   "metadata": {},
   "source": [
    "## Pull data from hf hub\n",
    "\n",
    "Since part of the dq processing involves tokenizing and aligning text / token indices, we work with a small real-world dataset - rather than dummy data.\n",
    "\n",
    "The Billsum dataset contains three columns:\n",
    "\n",
    "<p style=\"text-align: center;\">|| text || summary || title ||</p>\n",
    "\n",
    "We look at just **summary** and **title** and map them as follows:\n",
    "<p style=\"text-align: center;\">(summary, title) --> (input context,  target output)</p>\n",
    "\n",
    "We also use a small subset of the first 100(0?) data rows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "435be3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset billsum (/Users/jonathangomesselman/.cache/huggingface/datasets/billsum/default/3.0.0/75cf1719d38d6553aa0e0714c393c74579b083ae6e164b2543684e3e92e0c4cc)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c6e2131fe0446fb77edb2935245f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/jonathangomesselman/.cache/huggingface/datasets/billsum/default/3.0.0/75cf1719d38d6553aa0e0714c393c74579b083ae6e164b2543684e3e92e0c4cc/cache-8163760ca7c203c4.arrow\n",
      "Loading cached processed dataset at /Users/jonathangomesselman/.cache/huggingface/datasets/billsum/default/3.0.0/75cf1719d38d6553aa0e0714c393c74579b083ae6e164b2543684e3e92e0c4cc/cache-6f832c3394bf0964.arrow\n",
      "Loading cached processed dataset at /Users/jonathangomesselman/.cache/huggingface/datasets/billsum/default/3.0.0/75cf1719d38d6553aa0e0714c393c74579b083ae6e164b2543684e3e92e0c4cc/cache-fa696985d54ba920.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['summary', 'title', 'id'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = 100\n",
    "\n",
    "ds = load_dataset(\"billsum\")\n",
    "ds = ds.remove_columns('text')\n",
    "# Add ids\n",
    "ds = ds.map(lambda _, idx: {\"id\": idx}, with_indices=True)\n",
    "ds_train = Dataset.from_dict(ds['train'][:100])\n",
    "ds_val = Dataset.from_dict(ds['test'][:100])\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211edbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': \"Shields a business entity from civil liability relating to any injury or death occurring at a facility of that entity in connection with a use of such facility by a nonprofit organization if: (1) the use occurs outside the scope of business of the business entity; (2) such injury or death occurs during a period that such facility is used by such organization; and (3) the business entity authorized the use of such facility by the organization. \\nMakes this Act inapplicable to an injury or death that results from an act or omission of a business entity that constitutes gross negligence or intentional misconduct, including misconduct that: (1) constitutes a hate crime or a crime of violence or act of international terrorism for which the defendant has been convicted in any court; or (2) involves a sexual offense for which the defendant has been convicted in any court or misconduct for which the defendant has been found to have violated a Federal or State civil rights law. \\nPreempts State laws to the extent that such laws are inconsistent with this Act, except State law that provides additional protection from liability.  Specifies that this Act shall not be construed to supersede any Federal or State health or safety law. \\nMakes this Act inapplicable to any civil action in a State court against a business entity in which all parties are citizens of the State if such State, citing this Act's authority and containing no other provision, enacts a statute declaring the State's election that this Act shall not apply to such action in the State.\",\n",
       " 'title': 'A bill to limit the civil liability of business entities providing use of facilities to nonprofit organizations.',\n",
       " 'id': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ad8b2f",
   "metadata": {},
   "source": [
    "## Logging Data\n",
    "\n",
    "1. Before logging input data log the tokenizer (making sure we use the fast tokenizer)\n",
    "2. Log the input and target output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c78977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, GenerationConfig, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\", use_fast=True)\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Tokenize things\n",
    "def tokenize_outputs(row):\n",
    "    label_ids = tokenizer(row['title'])['input_ids']\n",
    "    return {'labels': label_ids}\n",
    "\n",
    "ds_train = ds_train.map(tokenize_outputs)\n",
    "ds_val = ds_val.map(tokenize_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "855297a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': \"Shields a business entity from civil liability relating to any injury or death occurring at a facility of that entity in connection with a use of such facility by a nonprofit organization if: (1) the use occurs outside the scope of business of the business entity; (2) such injury or death occurs during a period that such facility is used by such organization; and (3) the business entity authorized the use of such facility by the organization. \\nMakes this Act inapplicable to an injury or death that results from an act or omission of a business entity that constitutes gross negligence or intentional misconduct, including misconduct that: (1) constitutes a hate crime or a crime of violence or act of international terrorism for which the defendant has been convicted in any court; or (2) involves a sexual offense for which the defendant has been convicted in any court or misconduct for which the defendant has been found to have violated a Federal or State civil rights law. \\nPreempts State laws to the extent that such laws are inconsistent with this Act, except State law that provides additional protection from liability.  Specifies that this Act shall not be construed to supersede any Federal or State health or safety law. \\nMakes this Act inapplicable to any civil action in a State court against a business entity in which all parties are citizens of the State if such State, citing this Act's authority and containing no other provision, enacts a statute declaring the State's election that this Act shall not apply to such action in the State.\",\n",
       " 'title': 'A bill to limit the civil liability of business entities providing use of facilities to nonprofit organizations.',\n",
       " 'id': 0,\n",
       " 'labels': [71,\n",
       "  2876,\n",
       "  12,\n",
       "  2006,\n",
       "  8,\n",
       "  3095,\n",
       "  6283,\n",
       "  13,\n",
       "  268,\n",
       "  12311,\n",
       "  1260,\n",
       "  169,\n",
       "  13,\n",
       "  2465,\n",
       "  12,\n",
       "  11069,\n",
       "  2371,\n",
       "  5,\n",
       "  1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0642c70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathangomesselman/Galileo/codebase/dataquality/dataquality/core/__init__.py:27: GalileoWarning: configure is deprecated, use dq.set_console_url and dq.login\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¡ https://console.dev.rungalileo.io\n",
      "ðŸ”­ Logging you into Galileo\n",
      "\n",
      "ðŸš€ You're logged in to Galileo as galileo@rungalileo.io!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['GALILEO_CONSOLE_URL']=\"https://console.dev.rungalileo.io\"\n",
    "os.environ[\"GALILEO_USERNAME\"]=\"galileo@rungalileo.io\"\n",
    "os.environ[\"GALILEO_PASSWORD\"]=\"A11a1una!\"\n",
    "\n",
    "import dataquality as dq\n",
    "from dataquality.integrations.seq2seq.hf import watch\n",
    "dq.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3982d6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ¨ Initializing new public project 'Seq2Seq_ReArc_Encoder_Decoder'\n",
      "ðŸƒâ€â™‚ï¸ Creating new run '2023-11-08_1'\n",
      "ðŸ›° Connected to new project 'Seq2Seq_ReArc_Encoder_Decoder', and new run '2023-11-08_1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathangomesselman/Galileo/codebase/dataquality/dataquality/integrations/seq2seq/hf.py:81: UserWarning: The argument max_target_tokens is only used when working with EncoderDecoder models. This value will be ignored.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "dq.init(\"seq2seq\", project_name=\"Seq2Seq_ReArc_Encoder_Decoder\")\n",
    "\n",
    "temperature = 0.4\n",
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=15,\n",
    "    # Whether we use multinomial sampling\n",
    "    do_sample=temperature >= 1e-5,\n",
    "    temperature=temperature,\n",
    ")\n",
    "\n",
    "watch(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    generation_config,\n",
    "    generation_splits=['train'],\n",
    "    max_input_tokens=512,\n",
    "    max_target_tokens=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea763af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aligning characters with tokens:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging 100 samples [########################################] 100.00% elapsed time  :     0.00s =  0.0m =  0.0h\n",
      " "
     ]
    }
   ],
   "source": [
    "def log_dataset(ds, input_col=\"summary\", target_col=\"title\"):\n",
    "    dq.log_dataset(\n",
    "        ds,\n",
    "        text=input_col,\n",
    "        label=target_col,\n",
    "        split=\"training\"\n",
    "    )\n",
    "\n",
    "# Log just for training\n",
    "log_dataset(ds_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d9fc3a",
   "metadata": {},
   "source": [
    "## Logging Model Outputs\n",
    "Log 1 epoch of fake model output data: includes just logits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "523f57e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max seq len 111\n",
      "Doing batch 0\n"
     ]
    }
   ],
   "source": [
    "num_logits = len(tokenizer)\n",
    "batch_size = 100\n",
    "\n",
    "def log_epoch(ds):\n",
    "    ids = ds['id']\n",
    "    max_seq_length = np.max([len(ids) for ids in ds['labels']])\n",
    "    print(\"max seq len\", max_seq_length)\n",
    "    for i in range(0, len(ids), batch_size):\n",
    "        print (f\"Doing batch {i // batch_size}\")\n",
    "        batch_ids = ids[i: i + batch_size]\n",
    "        # Shape - [bs, max_seq_len, num_logits]\n",
    "        fake_logits = np.ones((batch_size, max_seq_length, num_logits))\n",
    "        dq.log_model_outputs(\n",
    "            logits = fake_logits,\n",
    "            ids = batch_ids\n",
    "        )\n",
    "\n",
    "dq.set_epoch(0)\n",
    "dq.set_split(\"train\")\n",
    "log_epoch(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8e363f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â˜ï¸ Uploading Data\n",
      "CuML libraries not found, running standard process. For faster Galileo processing, consider installing\n",
      "`pip install 'dataquality[cuda]' --extra-index-url=https://pypi.nvidia.com/`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9f4200827c41e8a380258376d66abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5fe28234450422a9bc4273d4181cff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batched Model Generation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training (epoch=0):   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading data to Galileo:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading data to Galileo:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading data to Galileo:   0%|          | 0.00/620k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job default successfully submitted. Results will be available soon at https://console.dev.rungalileo.io/insights/43b136da-dba3-43e4-a4ea-3db56d68636c/df5ddebd-e886-4732-9a77-0d83590a83d4?split=training&taskType=8\n",
      "Waiting for job (you can safely close this window)...\n",
      "\t[training] ðŸ‘€ Looking for data anomalies\n",
      "Done! Job finished with status completed\n",
      "ðŸ§¹ Cleaning up\n",
      "ðŸ§¹ Cleaning up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://console.dev.rungalileo.io/insights/43b136da-dba3-43e4-a4ea-3db56d68636c/df5ddebd-e886-4732-9a77-0d83590a83d4?split=training&taskType=8'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f766c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcore",
   "language": "python",
   "name": "mlcore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
