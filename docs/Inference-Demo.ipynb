{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef30b15",
   "metadata": {},
   "source": [
    "# Logging an inference run on production data\n",
    "\n",
    "In this notebook we learn how to log an inference run, demonstrating common flows and errors\n",
    "If you are new to the dataquality repo, check out the Dataquality-Client-Demo first!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6f195a",
   "metadata": {},
   "source": [
    "## Setup\n",
    "In this demo we use the same setup as the Dataquality-Client-Demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c49761dc-6330-4fca-af6b-1843441947c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GALILEO_CONSOLE_URL']=\"http://localhost:8088\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef6f76d6-1f13-407c-bad6-28d9e44bd69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have cloned the dataquality repo and are running this from the docs folder, you can run this\n",
    "#!pip install -q ../../../../dataquality\n",
    "import dataquality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4ed95c",
   "metadata": {},
   "source": [
    "Create an admin if one doesn't exist. Set admin credentials as environment variables to automatically login during `dataquality.init()` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ce730dc-a8ab-4d32-a07b-659861554ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "pwd = \"MyPassword!123\"\n",
    "\n",
    "data={\n",
    "  \"email\": \"me@rungalileo.io\",\n",
    "  \"first_name\": \"Me\",\n",
    "  \"last_name\": \"Me\",\n",
    "  \"username\": \"Galileo\",\n",
    "  \"auth_method\": \"email\",\n",
    "  \"password\": pwd\n",
    "}\n",
    "\n",
    "# This will silently fail with a requests status code of 400 if admin is already set\n",
    "r = requests.post(f'{dataquality.config.api_url}/users/admin', json=data)\n",
    "\n",
    "import os\n",
    "os.environ[\"GALILEO_USERNAME\"]=\"me@rungalileo.io\"\n",
    "os.environ[\"GALILEO_PASSWORD\"]=pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bc93a7",
   "metadata": {},
   "source": [
    "We create a few helper functions for creating and logging fake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6b2602e-afd9-4198-a65b-bbd1ff9f5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_dataset():\n",
    "    newsgroups = fetch_20newsgroups(subset=\"train\", remove=('headers', 'footers', 'quotes'))\n",
    "    dataset = pd.DataFrame()\n",
    "    dataset[\"text\"] = newsgroups.data\n",
    "    label_ind = newsgroups.target_names\n",
    "    dataset[\"label\"] = [label_ind[i] for i in newsgroups.target]\n",
    "    return dataset, label_ind\n",
    "\n",
    "def fetch_dataset(dataset, split, inference_name = None):\n",
    "    if split == \"training\":\n",
    "        return dataset[:100]\n",
    "    if split == \"test\":\n",
    "        return dataset[100:200]\n",
    "\n",
    "    if split == \"inference\":\n",
    "        if inference_name == \"03-14-2022\":\n",
    "            return dataset[200:300]\n",
    "        if inference_name == \"03-21-2022\":\n",
    "            return dataset[300:400]\n",
    "        if inference_name == \"all-customers\":\n",
    "            return dataset[400:500]\n",
    "\n",
    "    raise ValueError(\"Uh oh something happened\")\n",
    "\n",
    "# Generate fake model outputs\n",
    "def log_fake_data(dataset_len, log_num: int = 0):\n",
    "    num_rows = dataset_len // (log_num + 1)\n",
    "\n",
    "    emb = np.random.rand(num_rows, 800)\n",
    "    prob = np.random.rand(num_rows, 20)\n",
    "    for split in ['test','training']:\n",
    "        epoch = 0\n",
    "        \n",
    "        r = range(num_rows*log_num, num_rows*(log_num+1))\n",
    "        ids = list(r)\n",
    "        dataquality.log_model_outputs(emb=emb, probs=prob, split=split, epoch=epoch, ids=ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b8c6fd-419d-4444-b5f6-4b4ec2515b88",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Start with a train / test run\n",
    "\n",
    "Inference data will usually be logged after training / test runs. We simulate this flow by populating minio with training and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d385523-fb0d-48ce-9c5a-91bd462cab88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí≠ Project gonzaga was not found.\n",
      "‚ú® Initializing public project gonzaga\n",
      "üèÉ‚Äç‚ôÇÔ∏è Starting run duke\n",
      "üõ∞ Created project, gonzaga, and new run, duke.\n",
      "Exporting input data [########################################] 100.00% elapsed time  :     0.05s =  0.0m =  0.0h\n",
      "Appending input data [########################################] 100.00% elapsed time  :     0.01s =  0.0m =  0.0h\n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliottchartock/Code/dataquality/.venv/lib/python3.9/site-packages/dataquality/loggers/model_logger/text_classification.py:104: UserWarning: Usage of probs is deprecated, use logits instead\n",
      "  warnings.warn(\"Usage of probs is deprecated, use logits instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚òÅÔ∏è Uploading Data\n",
      "Combining batches for upload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a5be50cbb2420fa2ab3fa141171219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7be1e9792f2424eb25603a2e3b1422c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.06s =  0.0m =  0.0h\n",
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.12s =  0.0m =  0.0h\n",
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.19s =  0.0m =  0.0h\n",
      " Combining batches for upload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337feb69786e4a83825598f04ee467f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654d0bb97f6043119fb6b7984aec8cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.08s =  0.0m =  0.0h\n",
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.10s =  0.0m =  0.0h\n",
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.18s =  0.0m =  0.0h\n",
      " üßπ Cleaning up\n",
      "Job default successfully submitted. Results will be available soon at http://127.0.0.1:3000/insights?projectId=4878ec3b-95a6-46f7-afa8-f07af4969ade&runId=f6f72242-f668-41e6-9046-b18937072469&split=training&taskType=0&activeDepHigh=1&activeDepLow=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'project_id': '4878ec3b-95a6-46f7-afa8-f07af4969ade',\n",
       " 'run_id': 'f6f72242-f668-41e6-9046-b18937072469',\n",
       " 'job_name': 'default',\n",
       " 'labels': ['alt.atheism',\n",
       "  'comp.graphics',\n",
       "  'comp.os.ms-windows.misc',\n",
       "  'comp.sys.ibm.pc.hardware',\n",
       "  'comp.sys.mac.hardware',\n",
       "  'comp.windows.x',\n",
       "  'misc.forsale',\n",
       "  'rec.autos',\n",
       "  'rec.motorcycles',\n",
       "  'rec.sport.baseball',\n",
       "  'rec.sport.hockey',\n",
       "  'sci.crypt',\n",
       "  'sci.electronics',\n",
       "  'sci.med',\n",
       "  'sci.space',\n",
       "  'soc.religion.christian',\n",
       "  'talk.politics.guns',\n",
       "  'talk.politics.mideast',\n",
       "  'talk.politics.misc',\n",
       "  'talk.religion.misc'],\n",
       " 'tasks': None,\n",
       " 'non_inference_logged': False,\n",
       " 'message': 'Processing dataquality!',\n",
       " 'link': 'http://127.0.0.1:3000/insights?projectId=4878ec3b-95a6-46f7-afa8-f07af4969ade&runId=f6f72242-f668-41e6-9046-b18937072469&split=training&taskType=0&activeDepHigh=1&activeDepLow=0'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataquality.init(task_type=\"text_classification\", project_name=\"gonzaga\", run_name=\"duke\")\n",
    "base_dataset, labels = create_dataset()\n",
    "train_dataset = fetch_dataset(base_dataset, \"training\")\n",
    "dataquality.log_input_data(text=train_dataset['text'], labels=train_dataset['label'], split=\"training\")\n",
    "test_dataset = fetch_dataset(base_dataset, \"test\")\n",
    "dataquality.log_input_data(text=test_dataset['text'], labels=test_dataset['label'], split=\"test\")\n",
    "\n",
    "log_fake_data(len(train_dataset), 1)\n",
    "dataquality.set_labels_for_run(labels)\n",
    "dataquality.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f21452-bab3-4336-bfbf-a9e5e133d03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04ed792b-a786-4760-b740-9a83d7d9f400",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inference run\n",
    "\n",
    "Now log an inference run. Notice that when we log inference data it is appending to Minio, meaning that existing training / test data is not deleted. \n",
    "\n",
    "We can log multiple inference runs with different inference names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5af3a375-5fde-45ec-addf-657e504919c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(api_url='http://localhost:8088', minio_url='localhost:9000', minio_region='us-east-1', auth_method=<AuthMethod.email: 'email'>, token='eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJtZUBydW5nYWxpbGVvLmlvIiwiZXhwIjoxNjQ4MjE3MzI2fQ.wq8XqJuvgTUDlW7-wYZ1EnXTpD5kKPNqGyzQThGBpfw', current_user='me@rungalileo.io', current_project_id=UUID('18bca69e-ba3e-4b3f-b504-820124538a35'), current_run_id=UUID('39fa57ff-9c14-4af7-bb35-21efed1cb1a3'), task_type=<TaskType.text_classification: 'text_classification'>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataquality.init(task_type=\"text_classification\", project_name=\"gonzaga\", run_name=\"duke\")\n",
    "dataquality.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd45d726-0cce-4eae-97f1-e5d39d8ea73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"inference\"\n",
    "INFERENCE_NAMES = [\"03-14-2022\", \"03-21-2022\", \"all-customers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eed82d0-17d1-4909-8cd6-40b10cdc09b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset, labels = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "272b1e8f-6c29-47e2-bbbb-42c64bce94a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "week1_dataset = fetch_dataset(base_dataset, split, \"03-14-2022\")\n",
    "week2_dataset = fetch_dataset(base_dataset, split, \"03-21-2022\")\n",
    "all_dataset = fetch_dataset(base_dataset, split, \"all-customers\")\n",
    "datasets = {\n",
    "    \"03-14-2022\": week1_dataset,\n",
    "    \"03-21-2022\": week2_dataset,\n",
    "    \"all-customers\": all_dataset\n",
    "}\n",
    "starting_indices = {\n",
    "    \"03-14-2022\": 200,\n",
    "    \"03-21-2022\": 300,\n",
    "    \"all-customers\": 400\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "708c8ddc-c4a2-4fc2-8927-8711162f7ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>\\nI first read and consulted rec.guns in the s...</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>\\n\\nSeveral years ago GM was having trouble wi...</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>\\n   Great interview with Benjamin Netanyahu o...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>I apologize if this article is slightly confus...</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>\\nOh? Hellman said ``each user will get to cho...</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text                   label\n",
       "200  \\nI first read and consulted rec.guns in the s...      talk.politics.guns\n",
       "201  \\n\\nSeveral years ago GM was having trouble wi...               rec.autos\n",
       "202  \\n   Great interview with Benjamin Netanyahu o...   talk.politics.mideast\n",
       "203  I apologize if this article is slightly confus...  soc.religion.christian\n",
       "204  \\nOh? Hellman said ``each user will get to cho...               sci.crypt"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week1_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a7a2aea-ed58-46b0-ab57-2318c4ccdab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting input data [########################################] 100.00% elapsed time  :     0.01s =  0.0m =  0.0h\n",
      "Appending input data [########################################] 100.00% elapsed time  :     0.01s =  0.0m =  0.0h\n",
      "Appending input data [########################################] 100.00% elapsed time  :     0.01s =  0.0m =  0.0h\n",
      " "
     ]
    }
   ],
   "source": [
    "for inference_name in INFERENCE_NAMES:\n",
    "    starting_index = starting_indices[inference_name]\n",
    "    ids = list(range(starting_index, starting_index + 100))\n",
    "    # Inference doesn't expect labels, but does need an inference name\n",
    "    dataquality.log_input_data(\n",
    "        text=datasets[inference_name][\"text\"],\n",
    "        split=split,\n",
    "        inference_name=inference_name,  # could be removed if we only log 1 inference run at a time, would use stingified timestamp\n",
    "        ids=ids\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fbd0769-5ff6-4789-8779-3e943ef884f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_model_outputs(data, starting_index):\n",
    "    num_rows = len(data)\n",
    "    logits = np.random.rand(num_rows, 20) # fake logits\n",
    "    emb = np.random.rand(num_rows, 768) # fake embeddings\n",
    "    ids = list(range(starting_index, starting_index + 100))\n",
    "\n",
    "    return (emb, logits, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2cb0bbf-8d46-4417-9998-b25aeb634735",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inference_name in INFERENCE_NAMES:\n",
    "    # Set split takes in an optional inference name\n",
    "    dataquality.set_split(split, inference_name=inference_name)\n",
    "\n",
    "    emb, logits, ids = get_model_outputs(datasets[inference_name], starting_indices[inference_name])\n",
    "    dataquality.log_model_outputs(emb=emb, logits=logits, ids=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d764d8b-409e-4273-909a-653695ca5239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.galileo/logs/4878ec3b-95a6-46f7-afa8-f07af4969ade/f6f72242-f668-41e6-9046-b18937072469\u001b[0m\n",
      "‚îú‚îÄ‚îÄ \u001b[01;34minference\u001b[0m\n",
      "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ \u001b[01;34m03-14-2022\u001b[0m\n",
      "‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ \u001b[00madc39ca8873d.hdf5\u001b[0m\n",
      "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ \u001b[01;34m03-21-2022\u001b[0m\n",
      "‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ \u001b[00maa4ce70a2afe.hdf5\u001b[0m\n",
      "‚îÇ¬†¬† ‚îî‚îÄ‚îÄ \u001b[01;34mall-customers\u001b[0m\n",
      "‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ \u001b[00m4f923ed71598.hdf5\u001b[0m\n",
      "‚îî‚îÄ‚îÄ \u001b[00minput_data.arrow\u001b[0m\n",
      "\n",
      "4 directories, 4 files\n"
     ]
    }
   ],
   "source": [
    "!tree .galileo/logs/{dataquality.config.current_project_id}/{dataquality.config.current_run_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "751a88aa-ed04-434f-a2d1-e6a09922baeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚òÅÔ∏è Uploading Data\n",
      "Combining batches for upload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45606da646ac4ccfbb79c413df73bfde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c74fe4a0ae64829ad394c72ceaba34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "inference:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.07s =  0.0m =  0.0h\n",
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.06s =  0.0m =  0.0h\n",
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.25s =  0.0m =  0.0h\n",
      " Combining batches for upload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f675a582b641479db6e290798dfe8dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4665ba74e5842388a4354fb6a790f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "inference:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.05s =  0.0m =  0.0h\n",
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.05s =  0.0m =  0.0h \n",
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.28s =  0.0m =  0.0h\n",
      " Combining batches for upload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a80dd7db404e1084f8dcd2021530a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabfb29e88a148a48b1e17495838935a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "inference:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.05s =  0.0m =  0.0h\n",
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.06s =  0.0m =  0.0h\n",
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.26s =  0.0m =  0.0h\n",
      " üßπ Cleaning up\n",
      "Job inference successfully submitted. Results will be available soon at http://127.0.0.1:3000/insights?projectId=4878ec3b-95a6-46f7-afa8-f07af4969ade&runId=f6f72242-f668-41e6-9046-b18937072469&split=training&taskType=0&activeDepHigh=1&activeDepLow=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'project_id': '4878ec3b-95a6-46f7-afa8-f07af4969ade',\n",
       " 'run_id': 'f6f72242-f668-41e6-9046-b18937072469',\n",
       " 'job_name': 'inference',\n",
       " 'labels': ['alt.atheism',\n",
       "  'comp.graphics',\n",
       "  'comp.os.ms-windows.misc',\n",
       "  'comp.sys.ibm.pc.hardware',\n",
       "  'comp.sys.mac.hardware',\n",
       "  'comp.windows.x',\n",
       "  'misc.forsale',\n",
       "  'rec.autos',\n",
       "  'rec.motorcycles',\n",
       "  'rec.sport.baseball',\n",
       "  'rec.sport.hockey',\n",
       "  'sci.crypt',\n",
       "  'sci.electronics',\n",
       "  'sci.med',\n",
       "  'sci.space',\n",
       "  'soc.religion.christian',\n",
       "  'talk.politics.guns',\n",
       "  'talk.politics.mideast',\n",
       "  'talk.politics.misc',\n",
       "  'talk.religion.misc'],\n",
       " 'tasks': None,\n",
       " 'non_inference_logged': False,\n",
       " 'message': 'Processing dataquality!',\n",
       " 'link': 'http://127.0.0.1:3000/insights?projectId=4878ec3b-95a6-46f7-afa8-f07af4969ade&runId=f6f72242-f668-41e6-9046-b18937072469&split=training&taskType=0&activeDepHigh=1&activeDepLow=0'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finish will kickoff job with name \"inference\"\n",
    "dataquality.set_labels_for_run(labels)\n",
    "dataquality.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58fd8aa-02b1-4b32-989b-328ae070ae7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "745037d7-ce0e-4ef1-b3d9-3bb4b3b50945",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Log a new training run, inference data is wiped\n",
    "\n",
    "By default, logging a new training or test run wipes all Minio data. We log a new training run and can confirm that all data is wiped in the Minio bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40bd52b8-fe18-4ed5-bf30-816dc6655ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Retrieving run from existing project, gonzaga\n",
      "üõ∞ Connected to project, gonzaga, and run, duke.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliottchartock/Code/dataquality/.venv/lib/python3.9/site-packages/dataquality/core/init.py:145: UserWarning: Run: gonzaga/duke already exists! The existing run will get overwritten on call to finish()!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting input data [########################################] 100.00% elapsed time  :     0.00s =  0.0m =  0.0h\n",
      "Appending input data [########################################] 100.00% elapsed time  :     0.00s =  0.0m =  0.0h\n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliottchartock/Code/dataquality/.venv/lib/python3.9/site-packages/dataquality/loggers/model_logger/text_classification.py:104: UserWarning: Usage of probs is deprecated, use logits instead\n",
      "  warnings.warn(\"Usage of probs is deprecated, use logits instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚òÅÔ∏è Uploading Data\n",
      "Combining batches for upload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b0442f5c394a4b9e4d6bc9bada7c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d73e2e0b03475e96c99742d0dd945c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.04s =  0.0m =  0.0h\n",
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.10s =  0.0m =  0.0h\n",
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.22s =  0.0m =  0.0h\n",
      " Combining batches for upload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6935674a0dcf457e963b826ff2393fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1876cee000e04baf817015e65eba2d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.05s =  0.0m =  0.0h\n",
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.10s =  0.0m =  0.0h\n",
      "Writing data for upload [########################################] 100.00% elapsed time  :     0.19s =  0.0m =  0.0h\n",
      " üßπ Cleaning up\n",
      "Job default successfully submitted. Results will be available soon at http://127.0.0.1:3000/insights?projectId=18bca69e-ba3e-4b3f-b504-820124538a35&runId=39fa57ff-9c14-4af7-bb35-21efed1cb1a3&split=training&taskType=0&activeDepHigh=1&activeDepLow=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'project_id': '18bca69e-ba3e-4b3f-b504-820124538a35',\n",
       " 'run_id': '39fa57ff-9c14-4af7-bb35-21efed1cb1a3',\n",
       " 'job_name': 'default',\n",
       " 'labels': ['alt.atheism',\n",
       "  'comp.graphics',\n",
       "  'comp.os.ms-windows.misc',\n",
       "  'comp.sys.ibm.pc.hardware',\n",
       "  'comp.sys.mac.hardware',\n",
       "  'comp.windows.x',\n",
       "  'misc.forsale',\n",
       "  'rec.autos',\n",
       "  'rec.motorcycles',\n",
       "  'rec.sport.baseball',\n",
       "  'rec.sport.hockey',\n",
       "  'sci.crypt',\n",
       "  'sci.electronics',\n",
       "  'sci.med',\n",
       "  'sci.space',\n",
       "  'soc.religion.christian',\n",
       "  'talk.politics.guns',\n",
       "  'talk.politics.mideast',\n",
       "  'talk.politics.misc',\n",
       "  'talk.religion.misc'],\n",
       " 'tasks': None,\n",
       " 'non_inference_logged': False,\n",
       " 'message': 'Processing dataquality!',\n",
       " 'link': 'http://127.0.0.1:3000/insights?projectId=18bca69e-ba3e-4b3f-b504-820124538a35&runId=39fa57ff-9c14-4af7-bb35-21efed1cb1a3&split=training&taskType=0&activeDepHigh=1&activeDepLow=0'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataquality.init(task_type=\"text_classification\", project_name=\"gonzaga\", run_name=\"duke\")\n",
    "base_dataset, labels = create_dataset()\n",
    "train_dataset = fetch_dataset(base_dataset, \"training\")\n",
    "dataquality.log_input_data(text=train_dataset['text'], labels=train_dataset['label'], split=\"training\")\n",
    "test_dataset = fetch_dataset(base_dataset, \"test\")\n",
    "dataquality.log_input_data(text=test_dataset['text'], labels=test_dataset['label'], split=\"test\")\n",
    "\n",
    "log_fake_data(len(train_dataset), 1)\n",
    "dataquality.set_labels_for_run(labels)\n",
    "dataquality.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a316a5ae-f865-45f4-b413-90c77e81a4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
