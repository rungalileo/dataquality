{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ds = load_dataset(\\n    \"CVdatasets/CocoSegmentationOnlyVal5000\",\\n    use_auth_token=\"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\"\\n)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install datasets evaluate torch torchvision \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from coco_hf_datasets import (\n",
    "    expand_gray_channel, \n",
    "    download_gcs_data, \n",
    "    coco_hf_dataset_disk\n",
    ")\n",
    "\n",
    "'''ds = load_dataset(\n",
    "    \"CVdatasets/CocoSegmentationOnlyVal5000\",\n",
    "    use_auth_token=\"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\"\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat.jpeg',\n",
       " 'ui',\n",
       " 'Screenshot 2023-05-10 at 4.22.31 PM.png',\n",
       " 'Screenshot 2023-05-10 at 4.22.52 PM.png',\n",
       " 'hackathon.py',\n",
       " 'screenshot',\n",
       " '.DS_Store',\n",
       " 'Screenshot 2023-05-10 at 4.21.57 PM.png',\n",
       " 'Hyatt _ Reservation Confirmation.pdf',\n",
       " '.localized',\n",
       " '.bashrc',\n",
       " 'val2017',\n",
       " 'lease.pdf',\n",
       " 'Screenshot 2023-05-10 at 4.23.40 PM.png',\n",
       " 'OD',\n",
       " 'CV_datasets',\n",
       " '14D46FBC-BBC7-446D-B6CF-C3924EA12735.jpeg',\n",
       " 'datasets',\n",
       " 'tests',\n",
       " 'recreate',\n",
       " 'dojo',\n",
       " 'Screenshot 2023-05-10 at 4.21.43 PM.png',\n",
       " 'all_images',\n",
       " 'Screenshot 2023-04-14 at 10.48.39 AM.png',\n",
       " 'rungalileo',\n",
       " 'test.py',\n",
       " 'Screen Shot 2023-03-24 at 2.14.57 PM.png',\n",
       " 'Screenshot 2023-03-29 at 2.13.50 PM.png',\n",
       " 'annotations',\n",
       " 'Screenshot 2023-05-10 at 4.23.28 PM.png',\n",
       " 'dataquality',\n",
       " 'Screenshot 2023-05-10 at 4.22.41 PM.png',\n",
       " 'keypair',\n",
       " 'Screenshot 2023-05-10 at 4.22.18 PM.png',\n",
       " 'Hackathon.ipynb',\n",
       " 'dep',\n",
       " 'docker_images',\n",
       " 'beard_pic.jpeg',\n",
       " 'segmentation_datasets',\n",
       " 'api',\n",
       " 'ml papers',\n",
       " 'runners',\n",
       " 'ultralytics',\n",
       " 'random_scripts',\n",
       " 'cat_pic.jpeg',\n",
       " 'survey.csv',\n",
       " 'test.ipynb',\n",
       " 'Screenshot 2023-05-10 at 4.23.04 PM.png',\n",
       " 'Screen Shot 2023-02-22 at 1.52.33 PM.png',\n",
       " 'semantic_segmentation',\n",
       " 'llama',\n",
       " 'gpt4all']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dataset, there are 4030 images and 4030 masks\n"
     ]
    }
   ],
   "source": [
    "# download the data from our public gcs bucket and save it to disk\n",
    "# dataset_path, img_path, mask_path = download_gcs_data()\n",
    "dataset_path = \"/Users/derek/Desktop/CV_datasets\"\n",
    "img_path = \"COCO_seg_val_5000/all_images\"\n",
    "mask_path = \"COCO_seg_val_5000/all_masks\"\n",
    "\n",
    "IMG_SIZE = 128\n",
    "NC = 21  # Number of classes\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    expand_gray_channel(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "mask_transforms = transforms.Compose([\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "])\n",
    "\n",
    "\n",
    "coco_dataset = coco_hf_dataset_disk(dataset_path=dataset_path,\n",
    "                                    relative_img_path=img_path, \n",
    "                                    relative_mask_path=mask_path,\n",
    "                                    mask_transform=mask_transforms,\n",
    "                                    img_transform=img_transforms,\n",
    "                                    size=IMG_SIZE)\n",
    "coco_dataset = torch.utils.data.Subset(coco_dataset, range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_OAyVKtOSIQ_",
    "outputId": "85d91dc9-405e-4f02-a6bf-6a88f9502412",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/derek/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = .00001)\n",
    "\n",
    "# coco_hf = coco_hf_dataset(ds['train'], mask_transform=mask_transforms, img_transform=img_transforms, size=IMG_SIZE)\n",
    "train_loader = DataLoader(coco_dataset, batch_size=2, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/dataquality/core/__init__.py:27: GalileoWarning: configure is deprecated, use dq.set_console_url and dq.login\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° https://console.dev.rungalileo.io\n",
      "üî≠ Logging you into Galileo\n",
      "\n",
      "üöÄ You're logged in to Galileo as galileo@rungalileo.io!\n",
      "‚ú® Initializing existing public project 'Derek-Elliott-Proj'\n",
      "üèÉ‚Äç‚ôÇÔ∏è Fetching existing run 'test800'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/dataquality/core/init.py:148: GalileoWarning: Run: Derek-Elliott-Proj/test800 already exists! The existing run will get overwritten on call to finish()!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ∞ Connected to existing project 'Derek-Elliott-Proj', and existing run 'test800'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import dataquality as dq\n",
    "except:\n",
    "    import sys\n",
    "    sys.path.append(\"../../../dataquality/\")\n",
    "\n",
    "# os.environ['GALILEO_CONSOLE_URL']=\"http://localhost:8088\"\n",
    "# os.environ[\"GALILEO_USERNAME\"]=\"user@example.com\"\n",
    "# os.environ[\"GALILEO_PASSWORD\"]=\"Th3secret_\"\n",
    "\n",
    "os.environ['GALILEO_CONSOLE_URL']=\"https://console.dev.rungalileo.io/\"\n",
    "os.environ[\"GALILEO_USERNAME\"]=\"galileo@rungalileo.io\"\n",
    "os.environ[\"GALILEO_PASSWORD\"]=\"A11a1una!\"\n",
    "\n",
    "import dataquality as dq\n",
    "dq.configure()\n",
    "\n",
    "dq.init(\"semantic_segmentation\", \"Derek-Elliott-Proj\", 'test800')\n",
    "class_dict = { 'background': 0,\n",
    "                            'airplane': 1,\n",
    "                            'bicycle': 2,\n",
    "                            'bird': 3,\n",
    "                            'boat': 4,\n",
    "                            'bottle': 5,\n",
    "                            'bus': 6,\n",
    "                            'car': 7,\n",
    "                            'cat': 8,\n",
    "                            'chair': 9,\n",
    "                            'cow': 10,\n",
    "                            'dining table': 11,\n",
    "                            'dog': 12,\n",
    "                            'horse': 13,\n",
    "                            'motorcycle': 14,\n",
    "                            'person': 15,\n",
    "                            'potted plant': 16,\n",
    "                            'sheep': 17,\n",
    "                            'couch': 18,\n",
    "                            'train': 19,\n",
    "                            'tv': 20}\n",
    "reverse_class_dict = {v: k for k, v in class_dict.items()}\n",
    "dq.set_labels_for_run([reverse_class_dict[i] for i in range(NC)]) # 0 background, plus each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 07:57:24.556151: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We assume the dataloaders passed only have transforms that Tensor, Resize,         and Normalize the image and mask\n",
      "‚Äº Any cropping or shearing transforms passed will lead to unexpected         results\n",
      "See docs at https://dq.readthedocs.io/en/latest/ (placeholder) for more info         \n",
      " \n",
      "\n",
      "Found layer classifier in model layers: backbone, classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.91s/it]\n"
     ]
    }
   ],
   "source": [
    "from dataquality.integrations.cv.torch.semantic_segmentation import watch\n",
    "watch(\n",
    "    model,\n",
    "    bucket_name='https://storage.googleapis.com/galileo-public-data',\n",
    "    dataset_path=dataset_path,\n",
    "    dataloaders={\"training\": train_loader, \"validation\": train_loader}\n",
    ")\n",
    "epochs = 1\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "\n",
    "with torch.autocast('cuda'):\n",
    "    for epoch in range(epochs):\n",
    "        dq.set_epoch_and_split(epoch, \"training\")\n",
    "        for j, sample in enumerate(tqdm(train_loader)):\n",
    "            imgs, masks = sample['image'], sample['mask']\n",
    "            out = model(imgs.to(device))\n",
    "\n",
    "            # reshape to have loss for each pixel (bs * h * w, 21)\\n\",\n",
    "            pred = out['out'].permute(0, 2, 3, 1).contiguous().view( -1, 21)\n",
    "            masks = masks.long()\n",
    "            msks_for_loss = masks.view(-1).to(device)\n",
    "\n",
    "            loss = criterion(pred, msks_for_loss)\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            if j == 1: break\n",
    "        if epoch == 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:259: RuntimeWarning: invalid value encountered in divide\n",
      "  iou = total_area_intersect / total_area_union\n",
      "/Users/derek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging 2 samples [########################################] 100.00% elapsed time  :     0.27s =  0.0m =  0.0h\n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/dataquality/loggers/model_logger/base_model_logger.py:87: UserWarning: An issue occurred while logging model outputs. Address any issues in your logging and make sure to call dq.init before restarting:\n",
      "OSError('Unable to create file (unable to truncate a file which is already open)')\n",
      "  warnings.warn(err_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging 2 samples [########################################] 100.00% elapsed time  :     0.17s =  0.0m =  0.0h\n",
      "Logging 2 samples [########################################] 100.00% elapsed time  :     0.15s =  0.0m =  0.0h\n",
      " "
     ]
    },
    {
     "ename": "GalileoException",
     "evalue": "An issue occurred while logging model outputs. Address any issues in your logging and make sure to call dq.init before restarting:\nOSError('Unable to create file (unable to truncate a file which is already open)')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGalileoException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dq\u001b[39m.\u001b[39menable_galileo_verbose()\n\u001b[0;32m----> 2\u001b[0m dq\u001b[39m.\u001b[39;49mfinish()\n",
      "File \u001b[0;32m~/Desktop/dataquality/.venv/lib/python3.9/site-packages/dataquality/utils/helpers.py:25\u001b[0m, in \u001b[0;36mcheck_noop.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mif\u001b[39;00m galileo_disabled():\n\u001b[1;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/dataquality/.venv/lib/python3.9/site-packages/dataquality/core/finish.py:61\u001b[0m, in \u001b[0;36mfinish\u001b[0;34m(last_epoch, wait, create_data_embs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39m# Certain tasks require extra finish logic\u001b[39;00m\n\u001b[1;32m     59\u001b[0m data_logger\u001b[39m.\u001b[39mlogger_config\u001b[39m.\u001b[39mfinish()\n\u001b[0;32m---> 61\u001b[0m data_logger\u001b[39m.\u001b[39;49mupload(last_epoch, create_data_embs\u001b[39m=\u001b[39;49mcreate_data_embs)\n\u001b[1;32m     62\u001b[0m upload_dq_log_file()\n\u001b[1;32m     63\u001b[0m body \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m     64\u001b[0m     project_id\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(config\u001b[39m.\u001b[39mcurrent_project_id),\n\u001b[1;32m     65\u001b[0m     run_id\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(config\u001b[39m.\u001b[39mcurrent_run_id),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     feature_names\u001b[39m=\u001b[39mdata_logger\u001b[39m.\u001b[39mlogger_config\u001b[39m.\u001b[39mfeature_names,\n\u001b[1;32m     71\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/dataquality/.venv/lib/python3.9/site-packages/dataquality/loggers/data_logger/base_data_logger.py:229\u001b[0m, in \u001b[0;36mBaseGalileoDataLogger.upload\u001b[0;34m(self, last_epoch, create_data_embs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39massert\u001b[39;00m (\n\u001b[1;32m    226\u001b[0m     config\u001b[39m.\u001b[39mcurrent_project_id \u001b[39mand\u001b[39;00m config\u001b[39m.\u001b[39mcurrent_run_id\n\u001b[1;32m    227\u001b[0m ), \u001b[39m\"\u001b[39m\u001b[39mYou must call dq.init and train a model before calling finish\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m ThreadPoolManager\u001b[39m.\u001b[39mwait_for_threads()\n\u001b[0;32m--> 229\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_for_logging_failures()\n\u001b[1;32m    230\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m‚òÅÔ∏è Uploading Data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    231\u001b[0m object_store \u001b[39m=\u001b[39m ObjectStore()\n",
      "File \u001b[0;32m~/Desktop/dataquality/.venv/lib/python3.9/site-packages/dataquality/loggers/base_logger.py:354\u001b[0m, in \u001b[0;36mBaseGalileoLogger.check_for_logging_failures\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mlogger_config\u001b[39m.\u001b[39mexception:\n\u001b[1;32m    353\u001b[0m     upload_dq_log_file()\n\u001b[0;32m--> 354\u001b[0m     \u001b[39mraise\u001b[39;00m GalileoException(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mlogger_config\u001b[39m.\u001b[39mexception)\n",
      "\u001b[0;31mGalileoException\u001b[0m: An issue occurred while logging model outputs. Address any issues in your logging and make sure to call dq.init before restarting:\nOSError('Unable to create file (unable to truncate a file which is already open)')"
     ]
    }
   ],
   "source": [
    "dq.enable_galileo_verbose()\n",
    "dq.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:262: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dataquality.integrations.torch import unwatch\n",
    "unwatch(model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "vscode": {
   "interpreter": {
    "hash": "4347b986dc3664a7a202811703684c07cf3666bb8ef1e8f95a31bd6f0e89eb82"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06ab1078c7814f569f8824bdbf4aeb19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aba20a92a41e4e63ac20edd67c4ea747",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_829f93f0071d48c58447b62db05d0c6a",
      "value": "100%"
     }
    },
    "0a11ac35cf37495d8a1b75e3e11b45ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "28fe051f8a5e4b8ca7e58cdd31ba53a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_329c3de1151f4b2c987f5f58b1207132",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd1e7a8555104d3a92f0cff245ec324c",
      "value": 1
     }
    },
    "329c3de1151f4b2c987f5f58b1207132": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ce30c5b197148dd9a434981807ea73b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_06ab1078c7814f569f8824bdbf4aeb19",
       "IPY_MODEL_28fe051f8a5e4b8ca7e58cdd31ba53a9",
       "IPY_MODEL_8641549f7e08428db770154ac09b249e"
      ],
      "layout": "IPY_MODEL_c9e88f58ae2b48849599eccdb7e33d77"
     }
    },
    "829f93f0071d48c58447b62db05d0c6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8641549f7e08428db770154ac09b249e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8972779fefdf44e3a2078fc28a701f0b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0a11ac35cf37495d8a1b75e3e11b45ed",
      "value": " 1/1 [00:00&lt;00:00, 36.00it/s]"
     }
    },
    "8972779fefdf44e3a2078fc28a701f0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aba20a92a41e4e63ac20edd67c4ea747": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9e88f58ae2b48849599eccdb7e33d77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd1e7a8555104d3a92f0cff245ec324c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
