{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ds = load_dataset(\\n    \"CVdatasets/CocoSegmentationOnlyVal5000\",\\n    use_auth_token=\"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\"\\n)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install datasets evaluate torch torchvision \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from coco_hf_dataset import (\n",
    "    coco_hf_dataset_hf,\n",
    "    expand_gray_channel, \n",
    "    download_gcs_data, \n",
    "    coco_hf_dataset_disk\n",
    ")\n",
    "\n",
    "'''ds = load_dataset(\n",
    "    \"CVdatasets/CocoSegmentationOnlyVal5000\",\n",
    "    use_auth_token=\"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\"\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dataset, there are 4030 images and 4030 masks\n"
     ]
    }
   ],
   "source": [
    "# download the data from our public gcs bucket and save it to disk\n",
    "# dataset_path, img_path, mask_path = download_gcs_data()\n",
    "dataset_path = \"/Users/derek/Desktop/CV_datasets/COCO_seg_val_5000/\"\n",
    "img_path = \"all_images\"\n",
    "mask_path = \"all_masks\"\n",
    "\n",
    "IMG_SIZE = 128\n",
    "NC = 21  # Number of classes\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    expand_gray_channel(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "mask_transforms = transforms.Compose([\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "])\n",
    "\n",
    "\n",
    "coco_dataset = coco_hf_dataset_disk(dataset_path=dataset_path,\n",
    "                                    relative_img_path=img_path, \n",
    "                                    relative_mask_path=mask_path,\n",
    "                                    mask_transform=mask_transforms,\n",
    "                                    img_transform=img_transforms,\n",
    "                                    size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_OAyVKtOSIQ_",
    "outputId": "85d91dc9-405e-4f02-a6bf-6a88f9502412",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/derek/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = .00001)\n",
    "\n",
    "# coco_hf = coco_hf_dataset(ds['train'], mask_transform=mask_transforms, img_transform=img_transforms, size=IMG_SIZE)\n",
    "train_loader = DataLoader(coco_dataset, batch_size=2, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derek/Desktop/dataquality/docs/cv/../../../dataquality/dataquality/core/__init__.py:27: GalileoWarning: configure is deprecated, use dq.set_console_url and dq.login\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° https://console.dev.rungalileo.io\n",
      "üî≠ Logging you into Galileo\n",
      "\n",
      "üöÄ You're logged in to Galileo as galileo@rungalileo.io!\n",
      "‚ú® Initializing existing public project 'Derek-Elliott-Proj'\n",
      "üèÉ‚Äç‚ôÇÔ∏è Fetching existing run 'derek_test'\n",
      "üõ∞ Connected to existing project 'Derek-Elliott-Proj', and existing run 'derek_test'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derek/Desktop/dataquality/docs/cv/../../../dataquality/dataquality/core/init.py:148: GalileoWarning: Run: Derek-Elliott-Proj/derek_test already exists! The existing run will get overwritten on call to finish()!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import dataquality as dq\n",
    "except:\n",
    "    import sys\n",
    "    sys.path.append(\"../../../dataquality/\")\n",
    "\n",
    "# os.environ['GALILEO_CONSOLE_URL']=\"http://localhost:8088\"\n",
    "# os.environ[\"GALILEO_USERNAME\"]=\"user@example.com\"\n",
    "# os.environ[\"GALILEO_PASSWORD\"]=\"Th3secret_\"\n",
    "\n",
    "os.environ['GALILEO_CONSOLE_URL']=\"https://console.dev.rungalileo.io/\"\n",
    "os.environ[\"GALILEO_USERNAME\"]=\"galileo@rungalileo.io\"\n",
    "os.environ[\"GALILEO_PASSWORD\"]=\"A11a1una!\"\n",
    "\n",
    "import dataquality as dq\n",
    "dq.configure()\n",
    "\n",
    "dq.init(\"semantic_segmentation\", \"Derek-Elliott-Proj\", 'derek_test')\n",
    "# dq.init(\"semantic_segmentation\", \"Derek-Elliott-tests\", \"test_run\")\n",
    "class_dict = { 'background': 0,\n",
    "                            'airplane': 1,\n",
    "                            'bicycle': 2,\n",
    "                            'bird': 3,\n",
    "                            'boat': 4,\n",
    "                            'bottle': 5,\n",
    "                            'bus': 6,\n",
    "                            'car': 7,\n",
    "                            'cat': 8,\n",
    "                            'chair': 9,\n",
    "                            'cow': 10,\n",
    "                            'dining table': 11,\n",
    "                            'dog': 12,\n",
    "                            'horse': 13,\n",
    "                            'motorcycle': 14,\n",
    "                            'person': 15,\n",
    "                            'potted plant': 16,\n",
    "                            'sheep': 17,\n",
    "                            'couch': 18,\n",
    "                            'train': 19,\n",
    "                            'tv': 20}\n",
    "reverse_class_dict = {v: k for k, v in class_dict.items()}\n",
    "dq.set_labels_for_run([reverse_class_dict[i] for i in range(NC)]) # 0 background, plus each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We assume the dataloaders passed only have transforms that Tensor, Resize,         and Normalize the image and mask\n",
      "‚Äº Any cropping or shearing transforms passed will lead to unexpected         results\n",
      "See docs at https://dq.readthedocs.io/en/latest/ (placeholder) for more info         \n",
      " \n",
      "\n",
      "Attaching dataquality to model and dataloaders\n",
      "Found layer classifier in model layers: backbone, classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "  0%|          | 0/2015 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask column name is mask\n",
      "> \u001b[0;32m/Users/derek/Desktop/dataquality/dataquality/utils/semantic_segmentation/metrics.py\u001b[0m(150)\u001b[0;36mcalculate_mean_iou\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    148 \u001b[0;31m    \u001b[0;31m# for iou need shape (bs, 1, height, width) for some reason -\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    149 \u001b[0;31m    \u001b[0;31m# unsure if that is actually true but it works\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 150 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    151 \u001b[0;31m        iou = metric._compute(\n",
      "\u001b[0m\u001b[0;32m    152 \u001b[0;31m            \u001b[0mpred_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# tensor (1, height, width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "torch.Size([2, 128, 128])\n",
      "torch.Size([2, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:259: RuntimeWarning: invalid value encountered in divide\n",
      "  iou = total_area_intersect / total_area_union\n",
      "/Users/derek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/08bc20f4f895f3caf75fb9e3fada1404bded3c3265243d05327cbb3b9326ffe9/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_iou': 0.279402136107215, 'mean_accuracy': 0.46591635372238543, 'overall_accuracy': 0.798858642578125, 'per_category_iou': array([0.92407692,        nan,        nan, 0.        ,        nan,\n",
      "              nan,        nan, 0.        ,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.47293376,        nan, 0.        ,        nan,        nan,\n",
      "              nan]), 'per_category_accuracy': array([0.95681436,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan, 0.        ,        nan,        nan,\n",
      "              nan,        nan,        nan,        nan,        nan,\n",
      "       0.90685106,        nan, 0.        ,        nan,        nan,\n",
      "              nan])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derek/Desktop/dataquality/docs/cv/../../../dataquality/dataquality/loggers/model_logger/base_model_logger.py:76: UserWarning: An issue occurred while logging model outputs. Address any issues in your logging and make sure to call dq.init before restarting:\n",
      "BdbQuit()\n",
      "  self._log()\n",
      "  0%|          | 1/2015 [02:35<86:58:58, 155.48s/it]\n"
     ]
    },
    {
     "ename": "GalileoException",
     "evalue": "An issue occurred while logging model outputs. Address any issues in your logging and make sure to call dq.init before restarting:\nBdbQuit()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGalileoException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m j, sample \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[1;32m     14\u001b[0m     imgs, masks \u001b[39m=\u001b[39m sample[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m], sample[\u001b[39m'\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 15\u001b[0m     out \u001b[39m=\u001b[39m model(imgs\u001b[39m.\u001b[39;49mto(device))\n\u001b[1;32m     17\u001b[0m     \u001b[39m# reshape to have loss for each pixel (bs * h * w, 21)\\n\",\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     pred \u001b[39m=\u001b[39m out[\u001b[39m'\u001b[39m\u001b[39mout\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview( \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m21\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/dataquality/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1215\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1214\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m-> 1215\u001b[0m         hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39;49m, \u001b[39minput\u001b[39;49m, result)\n\u001b[1;32m   1216\u001b[0m         \u001b[39mif\u001b[39;00m hook_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1217\u001b[0m             result \u001b[39m=\u001b[39m hook_result\n",
      "File \u001b[0;32m~/Desktop/dataquality/docs/cv/../../../dataquality/dataquality/integrations/cv/torch/semantic_segmentation.py:163\u001b[0m, in \u001b[0;36mSemanticTorchLogger._dq_input_hook\u001b[0;34m(self, model, model_input, model_output)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mHook to store the model input (tensor) and extract the output\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39mfrom a dictionary and store\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m \n\u001b[1;32m    161\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhelper_data[HelperData\u001b[39m.\u001b[39mmodel_input] \u001b[39m=\u001b[39m model_input[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m--> 163\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_on_step_end()\n",
      "File \u001b[0;32m~/Desktop/dataquality/docs/cv/../../../dataquality/dataquality/integrations/cv/torch/semantic_segmentation.py:325\u001b[0m, in \u001b[0;36mSemanticTorchLogger._on_step_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"if not self.called_finish:\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m    return\"\"\"\u001b[39;00m\n\u001b[1;32m    310\u001b[0m logger \u001b[39m=\u001b[39m SemanticSegmentationModelLogger(\n\u001b[1;32m    311\u001b[0m     bucket_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbucket_name,\n\u001b[1;32m    312\u001b[0m     image_paths\u001b[39m=\u001b[39mimage_paths,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    323\u001b[0m     mislabeled_pixels\u001b[39m=\u001b[39mmislabeled_pixels,  \u001b[39m# torch tensor (bs, w, h)\u001b[39;00m\n\u001b[1;32m    324\u001b[0m )\n\u001b[0;32m--> 325\u001b[0m logger\u001b[39m.\u001b[39;49mlog()\n",
      "File \u001b[0;32m~/Desktop/dataquality/docs/cv/../../../dataquality/dataquality/loggers/model_logger/base_model_logger.py:96\u001b[0m, in \u001b[0;36mBaseGalileoModelLogger.log\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"The top level log function that try/excepts its child\"\"\"\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_for_logging_failures()\n\u001b[1;32m     97\u001b[0m     \u001b[39m# We validate split and epoch before entering the thread because we reference\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[39m# global variables (cur_split and cur_epoch) that are subject to change\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39m# between subsequent threads\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_split_epoch()\n",
      "File \u001b[0;32m~/Desktop/dataquality/docs/cv/../../../dataquality/dataquality/loggers/base_logger.py:354\u001b[0m, in \u001b[0;36mBaseGalileoLogger.check_for_logging_failures\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mlogger_config\u001b[39m.\u001b[39mexception:\n\u001b[1;32m    353\u001b[0m     upload_dq_log_file()\n\u001b[0;32m--> 354\u001b[0m     \u001b[39mraise\u001b[39;00m GalileoException(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mlogger_config\u001b[39m.\u001b[39mexception)\n",
      "\u001b[0;31mGalileoException\u001b[0m: An issue occurred while logging model outputs. Address any issues in your logging and make sure to call dq.init before restarting:\nBdbQuit()"
     ]
    }
   ],
   "source": [
    "from dataquality.integrations.cv.torch.semantic_segmentation import watch\n",
    "watch(model,\n",
    "            bucket_name='https://storage.googleapis.com/galileo-public-data',\n",
    "            dataset_path='../../../',\n",
    "            dataloaders =[train_loader, train_loader])\n",
    "epochs = 1\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "\n",
    "with torch.autocast('cuda'):\n",
    "    for epoch in range(epochs):\n",
    "        dq.set_epoch_and_split(epoch, \"training\")\n",
    "        for j, sample in enumerate(tqdm(train_loader)):\n",
    "            imgs, masks = sample['image'], sample['mask']\n",
    "            out = model(imgs.to(device))\n",
    "\n",
    "            # reshape to have loss for each pixel (bs * h * w, 21)\\n\",\n",
    "            pred = out['out'].permute(0, 2, 3, 1).contiguous().view( -1, 21)\n",
    "            masks = masks.long()\n",
    "            msks_for_loss = masks.view(-1).to(device)\n",
    "\n",
    "            loss = criterion(pred, msks_for_loss)\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            if j == 1: break\n",
    "        if epoch == 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running dataquality on dataloader:  Split.train\n",
      "Running dataquality on dataloader:  Split.val\n",
      "‚òÅÔ∏è Uploading Data\n",
      "CuML libraries not found, running standard process. For faster Galileo processing, consider installing\n",
      "`pip install 'dataquality[cuda]' --extra-index-url=https://pypi.ngc.nvidia.com/`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d7c627ad794c7881769418f7350047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing data for upload:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90619437640144f0abc83f399192e3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading data to Galileo:   0%|          | 0.00/34.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964161e782da4f4db42b047c76ad0e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing data for upload:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88ec230a94c4694abe2bcf0b36d772f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading data to Galileo:   0%|          | 0.00/32.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job default successfully submitted. Results will be available soon at https://console.dev.rungalileo.io/insights?projectId=c47fbac7-8d8b-42db-858e-369d49114339&runId=32167b1c-122c-46a3-a323-6233cb7f4e5b&split=training&metric=f1&depHigh=1&depLow=0&taskType=6\n",
      "Waiting for job (you can safely close this window)...\n",
      "Done! Job finished with status completed\n",
      "Click here to see your run! https://console.dev.rungalileo.io/insights?projectId=c47fbac7-8d8b-42db-858e-369d49114339&runId=32167b1c-122c-46a3-a323-6233cb7f4e5b&split=training&metric=f1&depHigh=1&depLow=0&taskType=6\n",
      "üßπ Cleaning up\n",
      "üßπ Cleaning up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://console.dev.rungalileo.io/insights?projectId=c47fbac7-8d8b-42db-858e-369d49114339&runId=32167b1c-122c-46a3-a323-6233cb7f4e5b&split=training&metric=f1&depHigh=1&depLow=0&taskType=6'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataquality.integrations.torch import unwatch\n",
    "unwatch(model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "vscode": {
   "interpreter": {
    "hash": "4347b986dc3664a7a202811703684c07cf3666bb8ef1e8f95a31bd6f0e89eb82"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06ab1078c7814f569f8824bdbf4aeb19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aba20a92a41e4e63ac20edd67c4ea747",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_829f93f0071d48c58447b62db05d0c6a",
      "value": "100%"
     }
    },
    "0a11ac35cf37495d8a1b75e3e11b45ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "28fe051f8a5e4b8ca7e58cdd31ba53a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_329c3de1151f4b2c987f5f58b1207132",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd1e7a8555104d3a92f0cff245ec324c",
      "value": 1
     }
    },
    "329c3de1151f4b2c987f5f58b1207132": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ce30c5b197148dd9a434981807ea73b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_06ab1078c7814f569f8824bdbf4aeb19",
       "IPY_MODEL_28fe051f8a5e4b8ca7e58cdd31ba53a9",
       "IPY_MODEL_8641549f7e08428db770154ac09b249e"
      ],
      "layout": "IPY_MODEL_c9e88f58ae2b48849599eccdb7e33d77"
     }
    },
    "829f93f0071d48c58447b62db05d0c6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8641549f7e08428db770154ac09b249e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8972779fefdf44e3a2078fc28a701f0b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0a11ac35cf37495d8a1b75e3e11b45ed",
      "value": " 1/1 [00:00&lt;00:00, 36.00it/s]"
     }
    },
    "8972779fefdf44e3a2078fc28a701f0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aba20a92a41e4e63ac20edd67c4ea747": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9e88f58ae2b48849599eccdb7e33d77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd1e7a8555104d3a92f0cff245ec324c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
