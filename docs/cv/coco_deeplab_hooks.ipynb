{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/derek/.cache/huggingface/datasets/CVdatasets___parquet/CVdatasets--CocoSegmentationOnlyVal5000-3602a99f2ad8587d/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e7bc55c3d545779e74f367b6534d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install datasets evaluate torch torchvision \n",
    "\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import evaluate\n",
    "from coco_hf_dataset import coco_hf_dataset, expand_gray_channel\n",
    "\n",
    "ds = load_dataset('CVdatasets/CocoSegmentationOnlyVal5000',  use_auth_token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_OAyVKtOSIQ_",
    "outputId": "85d91dc9-405e-4f02-a6bf-6a88f9502412",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/derek/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 64\n",
    "NC = 21  # Number of classes\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    expand_gray_channel(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "mask_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = .00001)\n",
    "\n",
    "coco_hf = coco_hf_dataset(ds['train'], mask_transform=mask_transforms, img_transform=img_transforms, size=IMG_SIZE)\n",
    "train_loader = DataLoader(coco_hf, batch_size=2, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTRIBUTING.md README.md       \u001b[34mdocs\u001b[m\u001b[m            pyproject.toml  \u001b[34mscripts\u001b[m\u001b[m\n",
      "LICENSE         \u001b[34mdataquality\u001b[m\u001b[m     mypy.ini        pytest.ini      \u001b[34mtests\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../dataquality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "/Users/derek/Desktop/dataquality/.venv/lib/python3.9/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "  0%|          | 0/2016 [00:00<?, ?it/s]\n"
     ]
    },
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/elliottchartock/Code/dataquality/.venv/lib/python3.9/site-packages/dataquality/loggers/model_logger/semantic_segmentation.py\u001b[0m(243)\u001b[0;36m_get_data_dict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    241 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    242 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 243 \u001b[0;31m        \u001b[0mdep_heatmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_dep_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    244 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_image_dep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdep_heatmaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    245 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "NameError: name 'y' is not defined\n",
      "> \u001b[0;32m/Users/elliottchartock/Code/dataquality/.venv/lib/python3.9/site-packages/dataquality/loggers/model_logger/semantic_segmentation.py\u001b[0m(243)\u001b[0;36m_get_data_dict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    241 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    242 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 243 \u001b[0;31m        \u001b[0mdep_heatmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_dep_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    244 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_image_dep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdep_heatmaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    245 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
=======
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m# log our batch - will need to do this automatically somehow\u001b[39;00m\n\u001b[1;32m     16\u001b[0m m\u001b[39m.\u001b[39mbl\u001b[39m.\u001b[39mbatch \u001b[39m=\u001b[39m sample\n\u001b[0;32m---> 17\u001b[0m out \u001b[39m=\u001b[39m model(imgs\u001b[39m.\u001b[39;49mto(device))\n\u001b[1;32m     19\u001b[0m \u001b[39m# reshape to have loss for each pixel (bs * h * w, 21)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m pred \u001b[39m=\u001b[39m out[\u001b[39m'\u001b[39m\u001b[39mout\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview( \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m21\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/dataquality/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1215\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1214\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m-> 1215\u001b[0m         hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39;49m, \u001b[39minput\u001b[39;49m, result)\n\u001b[1;32m   1216\u001b[0m         \u001b[39mif\u001b[39;00m hook_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1217\u001b[0m             result \u001b[39m=\u001b[39m hook_result\n",
      "File \u001b[0;32m~/Desktop/dataquality/docs/cv/../../../dataquality/dataquality/integrations/cv/torch/semantic_segmentation.py:52\u001b[0m, in \u001b[0;36mStoreHook.hook\u001b[0;34m(self, model, model_input, model_output)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_input \u001b[39m=\u001b[39m model_input\n\u001b[1;32m     51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_output \u001b[39m=\u001b[39m model_output[\u001b[39m\"\u001b[39m\u001b[39mout\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 52\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mon_finish(model_input, model_output)\n",
      "File \u001b[0;32m~/Desktop/dataquality/docs/cv/../../../dataquality/dataquality/integrations/cv/torch/semantic_segmentation.py:95\u001b[0m, in \u001b[0;36mManager._after_pred_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_ids \u001b[39m=\u001b[39m logging_data[\u001b[39m\"\u001b[39m\u001b[39midx\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()  \u001b[39m# np.ndarray (bs,)\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39m# dq log model output\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m logger \u001b[39m=\u001b[39m SemanticSegmentationModelLogger(\n\u001b[1;32m     96\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimg_ids,\n\u001b[1;32m     97\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgold_mask,\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mboundary_gold_masks,\n\u001b[1;32m     99\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mboundary_pred_masks,\n\u001b[1;32m    100\u001b[0m     logits\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogits,\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    102\u001b[0m logger\u001b[39m.\u001b[39mlog()\n",
      "File \u001b[0;32m~/Desktop/dataquality/docs/cv/../../../dataquality/dataquality/loggers/model_logger/semantic_segmentation.py:61\u001b[0m, in \u001b[0;36mSemanticSegmentationModelLogger.__init__\u001b[0;34m(self, image_ids, gt_masks, gold_boundary_masks, pred_boundary_masks, embs, probs, logits, ids, split, epoch, inference_name)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_boundary_masks \u001b[39m=\u001b[39m pred_boundary_masks\n\u001b[1;32m     60\u001b[0m \u001b[39m# assert ids is not None\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data_dict()\n",
      "File \u001b[0;32m~/Desktop/dataquality/docs/cv/../../../dataquality/dataquality/loggers/model_logger/semantic_segmentation.py:247\u001b[0m, in \u001b[0;36mSemanticSegmentationModelLogger._get_data_dict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpdb\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39m# pdb.set_trace()\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m dep_heatmaps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalculate_dep_heatmap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgt_masks)\n\u001b[1;32m    248\u001b[0m image_dep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalculate_image_dep(dep_heatmaps)\n\u001b[1;32m    249\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpdb\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/dataquality/docs/cv/../../../dataquality/dataquality/loggers/model_logger/semantic_segmentation.py:138\u001b[0m, in \u001b[0;36mSemanticSegmentationModelLogger.calculate_dep_heatmap\u001b[0;34m(self, probs, gt_masks, logits)\u001b[0m\n\u001b[1;32m    136\u001b[0m values \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(values, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)\n\u001b[1;32m    137\u001b[0m gt_indices \u001b[39m=\u001b[39m gt_masks\u001b[39m.\u001b[39mreshape((bs, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mexpand(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, values\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m])\n\u001b[0;32m--> 138\u001b[0m value_at_ground_truth \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mgather(values, \u001b[39m2\u001b[39;49m, gt_indices)[:, :, \u001b[39m0\u001b[39m]\n\u001b[1;32m    140\u001b[0m next_highest \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mclone()\n\u001b[1;32m    141\u001b[0m next_highest\u001b[39m.\u001b[39mscatter_(\u001b[39m2\u001b[39m, gt_indices, \u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as input tensor"
>>>>>>> 73b9a54fff05b42e63e08bbf4ea307f2e73a6c1a
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2016 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# log our batch - will need to do this automatically somehow\u001b[39;00m\n\u001b[1;32m     14\u001b[0m m\u001b[39m.\u001b[39mbl\u001b[39m.\u001b[39mbatch \u001b[39m=\u001b[39m sample\n\u001b[0;32m---> 15\u001b[0m out \u001b[39m=\u001b[39m model(imgs\u001b[39m.\u001b[39;49mto(device))\n\u001b[1;32m     17\u001b[0m \u001b[39m# reshape to have loss for each pixel (bs * h * w, 21)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m pred \u001b[39m=\u001b[39m out[\u001b[39m'\u001b[39m\u001b[39mout\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview( \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m21\u001b[39m)\n",
      "File \u001b[0;32m~/Code/dataquality/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1151\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1150\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m-> 1151\u001b[0m         hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39;49m, \u001b[39minput\u001b[39;49m, result)\n\u001b[1;32m   1152\u001b[0m         \u001b[39mif\u001b[39;00m hook_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1153\u001b[0m             result \u001b[39m=\u001b[39m hook_result\n",
      "File \u001b[0;32m~/Code/dataquality/.venv/lib/python3.9/site-packages/dataquality/integrations/cv/torch/semantic_segmentation.py:52\u001b[0m, in \u001b[0;36mStoreHook.hook\u001b[0;34m(self, model, model_input, model_output)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_input \u001b[39m=\u001b[39m model_input\n\u001b[1;32m     51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_output \u001b[39m=\u001b[39m model_output[\u001b[39m\"\u001b[39m\u001b[39mout\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 52\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mon_finish(model_input, model_output)\n",
      "File \u001b[0;32m~/Code/dataquality/.venv/lib/python3.9/site-packages/dataquality/integrations/cv/torch/semantic_segmentation.py:95\u001b[0m, in \u001b[0;36mManager._after_pred_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_ids \u001b[39m=\u001b[39m logging_data[\u001b[39m\"\u001b[39m\u001b[39midx\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()  \u001b[39m# np.ndarray (bs,)\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39m# dq log model output\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m logger \u001b[39m=\u001b[39m SemanticSegmentationModelLogger(\n\u001b[1;32m     96\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimg_ids,\n\u001b[1;32m     97\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgold_mask,\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mboundary_gold_masks,\n\u001b[1;32m     99\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mboundary_pred_masks,\n\u001b[1;32m    100\u001b[0m     logits\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogits,\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    102\u001b[0m logger\u001b[39m.\u001b[39mlog()\n",
      "File \u001b[0;32m~/Code/dataquality/.venv/lib/python3.9/site-packages/dataquality/loggers/model_logger/semantic_segmentation.py:61\u001b[0m, in \u001b[0;36mSemanticSegmentationModelLogger.__init__\u001b[0;34m(self, image_ids, gt_masks, gold_boundary_masks, pred_boundary_masks, embs, probs, logits, ids, split, epoch, inference_name)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_boundary_masks \u001b[39m=\u001b[39m pred_boundary_masks\n\u001b[1;32m     60\u001b[0m \u001b[39m# assert ids is not None\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data_dict()\n",
      "File \u001b[0;32m~/Code/dataquality/.venv/lib/python3.9/site-packages/dataquality/loggers/model_logger/semantic_segmentation.py:243\u001b[0m, in \u001b[0;36mSemanticSegmentationModelLogger._get_data_dict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpdb\u001b[39;00m\n\u001b[1;32m    241\u001b[0m pdb\u001b[39m.\u001b[39mset_trace()\n\u001b[0;32m--> 243\u001b[0m dep_heatmaps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalculate_dep_heatmap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgt_masks)\n\u001b[1;32m    244\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalculate_image_dep(dep_heatmaps)\n\u001b[1;32m    245\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpdb\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/dataquality/.venv/lib/python3.9/site-packages/dataquality/loggers/model_logger/semantic_segmentation.py:134\u001b[0m, in \u001b[0;36mSemanticSegmentationModelLogger.calculate_dep_heatmap\u001b[0;34m(self, probs, gt_masks, logits)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     values \u001b[39m=\u001b[39m probs\n\u001b[0;32m--> 134\u001b[0m y_indices \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mreshape((bs, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mexpand(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, values\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m])\n\u001b[1;32m    135\u001b[0m value_at_ground_truth \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mgather(values, \u001b[39m2\u001b[39m, y_indices)[:, :, \u001b[39m0\u001b[39m]\n\u001b[1;32m    137\u001b[0m next_highest \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mclone()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../dataquality')\n",
    "from dataquality.integrations.cv.torch.semantic_segmentation import Manager\n",
    "\n",
    "\n",
    "m = Manager(model, num_classes=NC)\n",
    "epochs = 1\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "with torch.autocast('cuda'):\n",
    "    for epoch in range(epochs):\n",
    "        for j, sample in enumerate(tqdm(train_loader)):\n",
    "            imgs, masks = sample['image'], sample['mask']\n",
    "            bs = imgs.shape[0]\n",
    "            # log our batch - will need to do this automatically somehow\n",
    "            m.bl.batch = sample\n",
    "            out = model(imgs.to(device))\n",
    "\n",
    "            # reshape to have loss for each pixel (bs * h * w, 21)\n",
    "            pred = out['out'].permute(0, 2, 3, 1).contiguous().view( -1, 21)\n",
    "            masks = masks.long()\n",
    "            msks_for_loss = masks.view(-1).to(device)\n",
    "\n",
    "            loss = criterion(pred, msks_for_loss)\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "\n",
    "            if j == 0: break\n",
    "        if epoch == 0: break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(in_images):\n",
    "    \"\"\"Goes from small float values to pixel values 0 to 255.\"\"\"\n",
    "    if isinstance(in_images, torch.Tensor):\n",
    "        images = in_images.clone().float()\n",
    "    else:\n",
    "        raise ValueError(\"Input must be tensor\")\n",
    "    if images[0].max() <= 1:\n",
    "        images *= 255  # de-normalise (optional)\n",
    "    if images.dim() != 4 or images.size(1) != 3:\n",
    "        raise ValueError(\"Input tensor must have shape (n, 3, w, h).\")\n",
    "    return images.permute(0, 2, 3, 1).to(torch.int8).cpu().numpy().astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.boundary_pred_masks.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "vscode": {
   "interpreter": {
    "hash": "4347b986dc3664a7a202811703684c07cf3666bb8ef1e8f95a31bd6f0e89eb82"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06ab1078c7814f569f8824bdbf4aeb19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aba20a92a41e4e63ac20edd67c4ea747",
      "placeholder": "​",
      "style": "IPY_MODEL_829f93f0071d48c58447b62db05d0c6a",
      "value": "100%"
     }
    },
    "0a11ac35cf37495d8a1b75e3e11b45ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "28fe051f8a5e4b8ca7e58cdd31ba53a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_329c3de1151f4b2c987f5f58b1207132",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd1e7a8555104d3a92f0cff245ec324c",
      "value": 1
     }
    },
    "329c3de1151f4b2c987f5f58b1207132": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ce30c5b197148dd9a434981807ea73b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_06ab1078c7814f569f8824bdbf4aeb19",
       "IPY_MODEL_28fe051f8a5e4b8ca7e58cdd31ba53a9",
       "IPY_MODEL_8641549f7e08428db770154ac09b249e"
      ],
      "layout": "IPY_MODEL_c9e88f58ae2b48849599eccdb7e33d77"
     }
    },
    "829f93f0071d48c58447b62db05d0c6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8641549f7e08428db770154ac09b249e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8972779fefdf44e3a2078fc28a701f0b",
      "placeholder": "​",
      "style": "IPY_MODEL_0a11ac35cf37495d8a1b75e3e11b45ed",
      "value": " 1/1 [00:00&lt;00:00, 36.00it/s]"
     }
    },
    "8972779fefdf44e3a2078fc28a701f0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aba20a92a41e4e63ac20edd67c4ea747": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9e88f58ae2b48849599eccdb7e33d77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd1e7a8555104d3a92f0cff245ec324c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
